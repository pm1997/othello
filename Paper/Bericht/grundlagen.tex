\chapter{Grundlagen}
\section{Spieltheorie}
\info{Einleitung fehlt}
\begin{Definition}[Spiel (Game)]
Ein \blue{Game} besteht aus einem Tupel der Form \\[0.2cm]
  \hspace*{1.3cm}
  $\mathcal{G} = \langle S\textsubscript{0},\mathtt{player}, \mathtt{actions}, \mathtt{result}, \mathtt{terminalTest}, \mathtt{utility} \rangle$
\\\so\ beschreibt den Startzustand des Spiels.
\\\textsc{player} ist auf der Menge der Spieler definiert und gibt den aktuellen Spieler zurück.
\\\textsc{actions} gibt die validen Folgezustände eines gegeben Zustands zurück.
\\\textsc{result} definiert das Resultat einer durchgeführten Aktion a und in einem Zustand s.
\\\textsc{terminalTest} prüft ob ein Zustand s ein Terminalzustand, also Endzustand, darstellt.
\\\textsc{utility} gibt einen Zahlenwert aus den Eingabenwerten s ( Terminalzustand) und p (Spieler) zurück. \\Positive Werte stellen einen Gewinn, negative Werte einen Verlust dar.
\info{quelle S.162}
\info{Definition States davor}
\end{Definition}
Eine spezielle Art von Spielen sind \blue{Nullsummenspiele}.
\begin{Definition}[Nullsummenspiele]
In einem \blue{Nullsummenspiel} ist die Summe der utility Funktion eines Zustands über alle Spieler 0. Dies bedeutet, dass wenn ein Spieler gewinnt mindestens ein Gegenspieler verliert.
\end{Definition}
Durch den Startzustand \so\ und der Funktion \textsc{action} wird ein \blue{Spielbaum (\gtree)} aufgespannt.
\begin{Definition}[Spielbaum (\gtree)]
Ein \blue{Spielbaum} besteht aus einer einzigen Wurzel, welche einen bestimmten Zustand (meistens \so) darstellt. Die Kindknoten der Wurzel stellen die durch \textsc{actions} erzeugten Zustände dar. Die Kanten zwischen der Wurzel und den Kindknoten stellen jeweils die durchgeführte Aktion dar, die ausgeführt wurde um vom State s zum Kindknoten zu gelangen.
\end{Definition}
\begin{Definition}[Suchbaum (Search Tree)]
Ein \blue{Suchbaum} ist ein Teil des Spielbaums.
\end{Definition}
\cite{Russell.2016}
\info{Überleitung einfügen}
\section{Spielstrategien}
Es gibt verschiedene Spielstrategien. Im Folgenden werden diese kurz erläutert und anschließend verglichen.
\subsection{Min-Max}
Der erste hier erläuterte Strategie ist der Min-Max Algorithmus. Dieser ist folgendermaßen definiert:
\\$MinMax(s) = \begin{cases} Utility(s)$; wenn TerminalTest(s) == true $\\max(\{a\textsubscript{e Actions(s)} MinMax(Result(s,a)\})$; wenn Spieler am Zug$\\min(\{a\textsubscript{e Actions(s)} MinMax(Result(s,a)\})$; wenn Gegner am Zug$\end{cases}$
\\Der Spieler sucht den bestmöglichen Zug aus \textsc{actions}, der ihm einen für seine Züge einen Vorteil schafft aber gleichzeitig nur \mxZitat{schlechte} Zugmöglichkeiten für den Gegner generiert. Der Gegner kann dadurch aus allen ehemals möglichen Zügen nicht den optimalen Zug spielen, da dieser in den aktuell enthaltenen Zügen nicht vorhanden ist. Er  wählt aus den verfügbaren \textsc{actions} nach den gleichen Vorgaben seinen besten Zug aus.
\\ Die Strategie ist eine Tiefensuche und erkundet jeden Knoten zuerst bis zu den einzelnen Blättern bevor ein Nachbarknoten ausgewählt wird. Dies setzt das mindestens einmalige Durchlaufen des gesamten Search Trees voraus. Bei einem durchschnittlichen Verzweigungsfaktor von $f$ bei einer Tiefe von $d$ resultiert daraus eine Komplexität von $O(d\textsuperscript{f})$. Bei einem einmaligen Erkunden der Knoten können die Werte aus den Blättern rekursiv von den Blättern zu den Knoten aktualisiert werden. Dadurch muss im nächsten Zug nur das Minimum aus \textsc{actions} ermittelt werden, da alle Kindknoten schon evaluiert wurden. Für übliche Spiele kann die Min-Max-Strategie allerdings nicht verwendet werden, da die Komplexität zu hoch für eine akzeptable Antwortzeit ist und der benötigte Speicherplatz für die berechneten Zustände sehr schnell wächst.
%\\\Tree [.A [.B [.C eins ] [.D zwei ] ].B [.E {3 und 4} ] ].A
\subsection{Alpha-Beta Pruning}
Der Min-Max Algorithmus berechnet nach dem Prinzip \mxZitat{depth-first} stets den kompletten \gtree. Bei der Betrachtung des Entscheidungsverhaltens des Algorithmus fällt jedoch schnell auf, dass ein nicht unerheblicher Teil aller möglichen Züge gar nicht erst in Betracht gezogen wird. Dies geschieht aufgrund der Tatsache, dass diese Züge in einem schlechteren Ergebnis resultieren würden als die letztendlich ausgewählten.\newline
Dem \abp\ Algorithmus liegt der Gedanke zugrunde, dass die Zustände, die in einem realen Spiel nie auftreten würden auch nicht berechnet werden müssen. Damit steht die dafür regulär erforderliche Rechenzeit und der entsprechende Speicher dafür zur Verfügung andere, vielversprechendere Zweige zu verfolgen.
\subsubsection{Demonstration an einem Beispiel}
\begin{figure}[ht]
\caption[]{Beispielhafter \gtree}
\Tree 
[.{A} 
	[.{B} 
		[.{E\\5} ].{E\\5} 
		[.{F\\13} ].{F\\13} 
		[.{G\\7} ].{G\\7} 
	].{B} 
	[.{C} 
		[.{H\\3} ].{H\\3}
		[.{I\\24} ].{I\\24}
		[.{J\\42} ].{J\\42} 
	].{C}
	[.{D} 
		[.{K\\42} ].{K\\42}
		[.{L\\6} ].{L\\6}
		[.{M\\1} ].{M\\1} 
	].{D} 
].{A}
\\\Tree 
[.{A\\$\alpha = -\infty$ $\beta = +\infty$} 
	[.{B\\$\alpha = -\infty$ $\beta = 5$} 
		[.{E\\5} ].{E\\5} 
		[.{F\\\grey{13}} ].{F\\\grey{13}} 
		[.{G\\\grey{7}} ].{G\\\grey{7}} 
	].{B\\$\alpha = -\infty$ $\beta = 5$} 
	[.{C\\\grey{$\alpha = ?$ $\beta = ?$}} 
		[.{H\\\grey{3}} ].{H\\\grey{3}}
		[.{I\\\grey{24}} ].{I\\\grey{24}}
		[.{J\\\grey{42}} ].{J\\\grey{42}} 
	].{C\\\grey{$\alpha = ?$ $\beta = ?$}}
	[.{D\\\grey{$\alpha = ?$ $\beta = ?$}} 
		[.{K\\\grey{42}} ].{K\\\grey{42}}
		[.{L\\\grey{6}} ].{L\\\grey{6}}
		[.{M\\\grey{1}} ].{M\\\grey{1}} 
	].{D\\\grey{$\alpha = ?$ $\beta = ?$}} 
].{A\\$\alpha = -\infty$ $\beta = +\infty$}
\Tree 
[.{A\\$\alpha = -\infty$ $\beta = +\infty$} 
	[.{B\\$\alpha = -\infty$ $\beta = 5$} 
		[.{E\\5} ].{E\\5} 
		[.{F\\13} ].{F\\13} 
		[.{G\\\grey{7}} ].{G\\\grey{7}} 
	].{B\\$\alpha = -\infty$ $\beta = 5$} 
	[.{C\\\grey{$\alpha = ?$ $\beta = ?$}} 
		[.{H\\\grey{3}} ].{H\\\grey{3}}
		[.{I\\\grey{24}} ].{I\\\grey{24}}
		[.{J\\\grey{42}} ].{J\\\grey{42}} 
	].{C\\\grey{$\alpha = ?$ $\beta = ?$}}
	[.{D\\\grey{$\alpha = ?$ $\beta = ?$}} 
		[.{K\\\grey{42}} ].{K\\\grey{42}}
		[.{L\\\grey{6}} ].{L\\\grey{6}}
		[.{M\\\grey{1}} ].{M\\\grey{1}} 
	].{D\\\grey{$\alpha = ?$ $\beta = ?$}} 
].{A\\$\alpha = -\infty$ $\beta = +\infty$}
\\\Tree 
[.{A\\$\alpha = 5$ $\beta = +\infty$} 
	[.{B\\$\alpha = 5$ $\beta = 5$} 
		[.{E\\5} ].{E\\5} 
		[.{F\\13} ].{F\\13} 
		[.{G\\7} ].{G\\7} 
	].{B\\$\alpha = 5$ $\beta = 5$} 
	[.{C\\\grey{$\alpha = ?$ $\beta = ?$}} 
		[.{H\\\grey{3}} ].{H\\\grey{3}}
		[.{I\\\grey{24}} ].{I\\\grey{24}}
		[.{J\\\grey{42}} ].{J\\\grey{42}} 
	].{C\\\grey{$\alpha = ?$ $\beta = ?$}}
	[.{D\\\grey{$\alpha = ?$ $\beta = ?$}} 
		[.{K\\\grey{42}} ].{K\\\grey{42}}
		[.{L\\\grey{6}} ].{L\\\grey{6}}
		[.{M\\\grey{1}} ].{M\\\grey{1}} 
	].{D\\\grey{$\alpha = ?$ $\beta = ?$}} 
].{A\\$\alpha = 5$ $\beta = +\infty$}
\Tree 
[.{A\\$\alpha = 5$ $\beta = +\infty$} 
	[.{B\\$\alpha = 5$ $\beta = 5$} 
		[.{E\\5} ].{E\\5} 
		[.{F\\13} ].{F\\13} 
		[.{G\\7} ].{G\\7} 
	].{B\\$\alpha = 5$ $\beta = 5$} 
	[.{C\\$\alpha = -\infty$ $\beta = 3$} 
		[.{H\\3} ].{H\\3}
		[.{I\\\grey{24}} ].{I\\\grey{24}}
		[.{J\\\grey{42}} ].{J\\\grey{42}} 
	].{C\\$\alpha = -\infty$ $\beta = 3$}
	[.{D\\\grey{$\alpha = ?$ $\beta = ?$}} 
		[.{K\\\grey{42}} ].{K\\\grey{42}}
		[.{L\\\grey{6}} ].{L\\\grey{6}}
		[.{M\\\grey{1}} ].{M\\\grey{1}} 
	].{D\\\grey{$\alpha = ?$ $\beta = ?$}} 
].{A\\$\alpha = 5$ $\beta = +\infty$}
\\\Tree 
[.{A\\$\alpha = 5$ $\beta = 42$} 
	[.{B\\$\alpha = 5$ $\beta = 5$} 
		[.{E\\5} ].{E\\5} 
		[.{F\\13} ].{F\\13} 
		[.{G\\7} ].{G\\7} 
	].{B\\$\alpha = 5$ $\beta = 5$} 
	[.{C\\$\alpha = -\infty$ $\beta = 3$} 
		[.{H\\3} ].{H\\3}
		[.{I\\\grey{24}} ].{I\\\grey{24}}
		[.{J\\\grey{42}} ].{J\\\grey{42}} 
	].{C\\$\alpha = -\infty$ $\beta = 3$}
	[.{D\\$\alpha = -\infty$ $\beta = 42$} 
		[.{K\\42} ].{K\\42}
		[.{L\\\grey{6}} ].{L\\\grey{6}}
		[.{M\\\grey{1}} ].{M\\\grey{1}} 
	].{D\\$\alpha = -\infty$ $\beta = 42$}  
].{A\\$\alpha = 5$ $\beta = 42$}
\Tree 
[.{A\\$\alpha = 5$ $\beta = 5$} 
	[.{B\\$\alpha = 5$ $\beta = 5$} 
		[.{E\\5} ].{E\\5} 
		[.{F\\13} ].{F\\13} 
		[.{G\\7} ].{G\\7} 
	].{B\\$\alpha = 5$ $\beta = 5$} 
	[.{C\\$\alpha = -\infty$ $\beta = 3$} 
		[.{H\\3} ].{H\\3}
		[.{I\\\grey{24}} ].{I\\\grey{24}}
		[.{J\\\grey{42}} ].{J\\\grey{42}} 
	].{C\\$\alpha = -\infty$ $\beta = 3$}
	[.{D\\$\alpha = 1$ $\beta = 1$} 
		[.{K\\42} ].{K\\42}
		[.{L\\6} ].{L\\6}
		[.{M\\1} ].{M\\1} 
	].{D\\$\alpha = 1$ $\beta = 1$}  
].{A\\$\alpha = 5$ $\beta = 5$}
\end{figure}
Um den Algorithmus zu verdeutlichen betrachten wir das, an \improvement{Quelle Norvig Hinzufügen, Verweis auf Abbildung einfügen} XXX angelehnte, folgende Beispiel. Das dargestellte Spiel besteht aus lediglich zwei Zügen, die abwechselnd durch die Spieler gewählt werden. An den Knoten der untersten Ebene des \gtree\ werden die Werte der Zustände gemäß der \textsc{utility} Funktion angegeben. Die Werte $\alpha$ und $\beta$ geben den schlechtmöglichsten bzw. den bestmöglichen Spielausgang für einen Zweig, immer aus der Sicht des beginnenden Spielers, an. Die ausgegrauten Knoten wurden noch nicht betrachtet.\\
Betrachten wir nun den linken Baum in der zweiten Zeile: Der Algorithmus beginnt damit alle möglichen Folgezustände bei der Wahl von B als Folgezustand zu evaluieren. Dabei wird zunächst der Knoten E betrachtet und damit der Wert 5 ermittelt. Dies ist der bisher beste Wert. Er wird als $\beta$ gespeichert. Eine Aussage\improvement{Warum} über den schlechtesten Wert kann noch nicht getroffen werden.\\
Im nachfolgenden \gtree\ wird der nächste Schritt verdeutlicht. Es wird der Knoten F betrachtet. Dieser hat einen Wert von 13. Am Zuge ist jedoch der zweite Spieler. Dieser wird, geht man davon aus, dass er ideal spielt, jedoch keinen Zug wählen der ein besseres Ergebnis für den Gegner bringt als unbedingt nötig. Der bestmögliche Wert für den ersten Spieler bleibt damit 5.\\
Nach der Auswertung des Knotens G steht fest, dass es keinen besseren und keinen schlechteren Wert aus Sicht des ersten Spielers gibt. Daraufhin wird die 5 auch als schlechtester Wert in $\alpha$ gespeichert. Ausgehend von A  ist der schlechteste Wert damit 5 ggf. kann jedoch noch ein besseres Ergebnis herbeigeführt werden. $\alpha$ wird entsprechend gesetzt und $\beta$ verbleibt undefiniert.\\
Nun werden die Kindknoten von C betrachtet. Mit einem Wert von 3 wäre der Knoten H das bisher beste Ergebnis für die Wahl von C. Der Wert wird entsprechend gespeichert. Würde C gewählt gäbe man dem Gegenspieler die Chance ein im Vergleich zu der Wahl des Knotens B schlechteres Ergebnis herbeizuführen. Da Ziel des Spielers jedoch ist die eigenen Punkte zu maximieren gilt es diese Chance gar nicht erst zu gewähren. Entsprechend werden die Auswertung der weiteren Knoten abgebrochen.\\
Der Kindknoten K des Knotens D ist mit einem Wert von 42 vielversprechend und wird in $\beta$ gespeichert. Da dieser Wert größer ist als die gespeicherten 5 wird auch der entsprechende Wert von A aktualisiert. Der anschließend ausgewertete Knoten L ermöglicht nun ein schlechteres Ergebnis von 6 $\beta$ muss also aktualisiert werden. Der Knoten M liefert schließlich den schlechtesten Wert von 1. Da der Gegenspieler im Zweifel diesen Wert wählen würde bleibt der bisher beste Wert das Ergebnis in E. In A wird der Spieler daher B auswählen
\paragraph{}  
Dieses einfache Beispiel zeigt bereits recht gut wie die Auswertung von weiteren Zweigen vermieden werden kann. In der Praktischen Anwendung befinden sich die wegfallenden Zustände häufig nicht nur in den Blättern des Baumes sondern auch auf höheren Ebenen. Der eingesparte Aufwand wird dadurch häufig noch größer.  

\subsubsection{Implementierung}
Nachfolgend wird eine Pseudoimplementierung des um Alpha-Beta Pruning erweiterten MinMax Algorithmus angegeben.:
\begin{lstlisting}
global Suchtiefe
int minMax(Spiel AktuellerZustand, int Spieler, int Tiefe, int alpha, int beta) {
	if (Tiefe == 0) {
		return Utility(AktuellerZustand, Spieler);	
	}
	int bisherigerMaximalWert = alpha
	Zuege = mengeDerFolgezuege(aktuellerZustand);
	for (Zug z in Zuege) {
		Spiel NeuerZustand = wähleZug(Aktueller Zustand, z)
		wert = -minMax(NeuerZustand, anderer(Spieler), Tiefe-1, -beta, -bisherigerMaximalWert)
		if (wert > bisherigerMaximalWert) {
			bisherigerMaximalWert = wert
			if (bisherigerMaximalWert >= beta) {
				break;
			}
			if (Tiefe = Suchtiefe) {
				speichereZug(z)
			}
		}
	}
	return bisherigerMaximalwert;		
} 
\end{lstlisting}
Es handelt sich um eine rekursive Implementierung. Im Basisfall ist der Gametree bereits bis in die angegebene Suchtiefe erforscht. In diesem Fall wird der Wert der Utility Funktion für den aktuellen Spieler bei dem aktuellen Zustand zurückgegeben.
\paragraph{}
Handelt es sich nicht um einen solchen Fall werden alle möglichen Folgezüge betrachtet.
Um den Wert des Zuges zu bestimmen wird rekursiv die minMax-Methode erneut aufgerufen. Dabei wird entsprechend der Neue Zustand, der andere Spieler und eine um die um eins verringerte Tiefe übergeben. Der beste Wert für den anderen Spieler ist der schlechteste wert für den ersten Spieler. Daher wird der bisherige Wert von beta als alpha übergeben. Der bisher beste Wert ist aus sicht des anderen Spielers der schlechteste daher wird dieser als neues beta Übergeben. Da die Utility Funktion so implementiert ist, dass die Summe der Wertigkeiten eines Zustandes Null ergibt muss noch das Vorzeichen geändert werden.\\
Ist der neue Wert größer als der bisherige Maximalwert so wird dieser aktualisiert.
Da der zweite Spieler versucht die Punktzahl des Gegners zu maximieren bricht dieser die Auswertung aller Zweige ab bei der ein Ergebnis, welches besser ist als das bisher schlechteste Ergebnis, möglich wird.
Abschließend wird der ausgewertete Zug gespeichert um ihn später ausführen zu können.
\subsubsection{Ordnung der Züge}
Wie in obigen Beispiel an den Zweigen unter dem Knoten C zu sehen war kann, je nach der Reihenfolge in der die Folgezüge untersucht werden, die Auswertung eines Folgezustandes früher oder später abgebrochen werden. Optimalerweise werden die besten Züge, also jene Züge die einen möglichst frühen Abbruch der Betrachtung eines Knotens herbeiführen zuerst betrachtet. Um dies Abschätzen zu können bedient man sich in der Praxis einer Heuristik die Aussagen über die Güte eines Zuges im Vergleich zu den übrigen Zügen zulässt. Anhand dieser Heuritik kann dann die Reihenfolge der Auswertung einzelner Folgezustände dynamisch angepasst werden.

\subsection{Suboptimale Echtzeitentscheidungen}
Selbst die gezeigten Verbesserung des MinMax-Algorithmus besitzt noch einen wesentlichen Nachteil. Da es sich um einen "depth-first" Algorithmus handelt muss jeder Pfad bis zu einem Endzustand betrachtet werden um eine Aussage über den Wert des Zuges treffen zu können. Dem steht jedoch die Tatsache entgegen, dass in der Praxis eine Entscheidung möglichst schnell, idealer Weise innerhalb weniger Minuten, getroffen werden soll. Hinzu kommt, dass je nach der verwendeten Datenstruktur für ein Spiel bei entsprechend hohem Verzweigungsfaktor und einer großen Anzahl von Zügen der Hauptspeicher eines handelsüblichen Computers nicht mehr ausreicht um diese zu fassen\\
Es gilt also eine Möglichkeit zu finden, die Auswertung des kompletten Baumes zu vermeiden.

\subsubsection{Heuristiken}
Dieses Problem lösen sogenannte Heuristiken. Dabei handelt es sich um eine Funktion die den Wert eines Spielzustandes annähert.\\
\improvement{consistent/admissible}
Die Nutzung der Heuristik wird vereinfacht, wenn Sie so definiert ist, dass sie, sofern es sich um einen Endzustand handelt den Wert der Utility Funktion zurückgibt. Der Vorteil dieses Verhaltens wird im nächsten Abschnitt betrachtet.\\
Kommt eine Heuristik zur Anwendung so ist die Genauigkeit mit der diese den tatsächlichen Wert approximiert der wesentliche Aspekt der die Qualität des Spiel-Algorithmus ausmacht. Um zu verhindern, das versehntlich die besten Züge nicht betrachtet werden, ist es essentiell, dass eine Heuristik den tatsächlichen Wert eines Zustandes nie überschätzt. Das unterschätzen des Wertes hingegen ist möglich darf im Sinne der Genauigkeit der Heuristik jedoch nicht allzu ungleichmäßig Auftreten.

\subsubsection{Abschnittkriterium der Suche}
Gibt die Heuristik im Falle eines Endzustandes den Wert der Utility Funktion zurück so kann die oben gezeigte Implementierung so angepasst werden, dass statt der Utility Funktion einfach die Heuristik ausgewertet wird. Dadurch muss nicht mehr der Vollständige Zweig durchsucht werden und das Abbrechen nach einer gewissen Suchtiefe wird möglich.
 
\subsubsection{Forward pruning}
Forward pruning durchsucht nicht den kompletten \gtree , sondern durchsucht nur einen Teil. Eine Möglichkeit ist eine Strahlensuche, welche nur die \mxZitat{besten} Züge durchsucht. Die Züge mit einer geringen Erfolgswahrscheinlichkeit werden abgeschnitten und nicht bis zum Blattknoten evaluiert. Durch die Wahl des jeweils wahrscheinlichten Zuges können aber auch sehr gute bzw. schlechte Züge nicht berücksichtigt werden, da sie eine geringe Wahrscheinlichkeit besitzen. Durch das Abschneiden von Teilen des \gtree\ wird die Suchgeschwindigkeit deutlich erhöht. Der in dem Othello-Programm \mxZitat{Logistello} verwendete \mxZitat{Probcut} erzielt außerdem eine Gewinnwahrscheinlichkeit von 64\% gegenüber der ursprünglichen Version ohne Forward pruning.
\subsubsection{Search versus lookup}
Viele Spiele kann man in 3 Haupt-Spielabschnitte einteilen:
\begin{itemize}
\item Eröffnungsphase
\item Mittelspiel
\item Endphase
\end{itemize}
In der Eröffnungsphase und in der Endphase gibt es im Vergleich zum Mittelspiel wenige Zugmöglichkeiten. Dadurch sinkt der Verzweigungsfaktor und die generelle Anzahl der states. In diesen Phasen können die optimalen Spielzüge einfacher berechnet werden. Eine weitere Möglichkeit besteht aus dem Nachschlagen des \states\ aus einer Lookup-Tabelle.
Dies ist sinnvoll, da gewöhnlicherweise sehr viel Literatur über die Spieleröffnung des jeweiligen Spiels existiert. Auch über die Endzustände in der Schlussphase des Spiels findet sich Literatur. Das Mittelspiel jedoch hat zu viele Zugmöglichkeiten, um eine Tabelle der möglichen Spielzüge bis zum Spielende aufstellen zu können. In dem Kapitel \ref{othello-chapter} werden die bekanntesten Eröffnungsstrategien aufgelistet.