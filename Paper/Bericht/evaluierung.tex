\chapter{Evaluierung}
Die in Kapitel \ref{implementation} erklärten Agenten werden nun verglichen. Sie werden einerseits in den Standardeinstellungen verglichen, als auch mit anderen Einstellungen, beispielsweise mit verschiedenen Heuristiken. Die Standardeinstellungen der Agenten wurden empirisch an eine Laufzeit von fünf Minuten je Spiel und Agent angenähert. Dies war eine Vorgabe, dass jedem Agent etwa fünf Minuten Berechnungszeit zur Verfügung steht.
In der folgenden Tabelle sind die in diesem Kapitel evaluierten Agenten aufgelistet.
\begin{table}[ht]
\begin{center}
\begin{tabular}{| c | c | c |} \hline
Vergleich & Agent 1 & Agent 2 \\ \hline
1 & Random & Monte Carlo  \\ \hline
2 & Monte Carlo & Random\\ \hline
3 & Random & Alpha-Beta\\ \hline
4 & Alpha-Beta & Random\\ \hline
5 & Alpha-Beta: Nijssen 2007 Heuristik & Random\\ \hline
6 & Alpha-Beta: Cowthello Heuristik & Random\\ \hline
7 & Random & Alpha-Beta: Nijssen 2007 Heuristik \\ \hline
8 & Random & Alpha-Beta: Cowthello Heuristik \\ \hline
9 & Alpha-Beta: Nijssen 2007 Heuristik & Monte Carlo\\ \hline
10 & Alpha-Beta: Cowthello Heuristik & Monte Carlo\\ \hline
11 & Monte Carlo & Alpha-Beta: Nijssen 2007 Heuristik \\ \hline
12 & Monte Carlo & Alpha-Beta: Cowthello Heuristik \\ \hline
\end{tabular}
\end{center}
\caption{Liste der Äquivalenzklassen}
\label{agents1}
\end{table}

Die in dieser Tabelle aufgeführten Vergleiche werden in den folgenden Unterkapiteln durchgeführt und die Ergebnisse evaluiert.
Um ein aussagekräftiges Ergebnis ermitteln zu können, werden jeweils 100 Spiele pro Vergleich durchgeführt. Da ein Unterschied existiert, welcher Agent den ersten Zug durchführt, werden beide Kombinationen verglichen.
\section{Random vs. Monte Carlo}
In diesem Vergleich werden die Agenten \mxZitat{Random} und \mxZitat{Monte Carlo} in Standardkonfiguration verglichen. Dies bedeutet, dass \mxZitat{Monte Carlo} 1400 zufällige Spiele je Zug durchführt und dadurch den \mxZitat{besten} Zug ermittelt.
Die Auswertung ergab folgende Ergebnisse:
\begin{itemize}
\item Ein durchschnittliches Spiel dauert Minuten.
\item Der Agent \mxZitat{Random} gewann Spiele.
\item Der Agent \mxZitat{Monte Carlo} gewann Spiele.
\end{itemize}
Aus diese Ergebnissen können unentschiedene Spiele abgeleitet werden. Der Vergleich mit dem \mxZitat{Random} Agenten soll die grundsätzliche Leistungsfähigkeit des Agenten darstellen. Statistisch ist die Gewinnwahrscheinlichkeit des \mxZitat{Random} Agenten 50 Prozent. Je höher die Gewinnwahrscheinlichkeit des \mxZitat{Monte Carlo} Agenten ist, dh. je mehr sie von den 50 Prozent abweicht, desto besser ist der Agent. Ist die Wahrscheinlichkeit nur minimal besser als 50 Prozent, ist der Agent nicht sehr gut, da durch simples Raten eine Gewinnwahrscheinlichkeit von 50 Prozent erreicht wird.
\section{Monte Carlo vs Random}

\section{Random vs Alpha-Beta}

\section{Alpha-Beta vs Random}

\section{Alpha-Beta: Nijssen 2007 Heuristik vs Random}

\section{Alpha-Beta: Cowthello Heuristik vs Random}

\section{Random vs Alpha-Beta: Nijssen 2007 Heuristik}

\section{Random vs Alpha-Beta: Cowthello Heuristik}

\section{Alpha-Beta: Nijssen 2007 Heuristik vs Monte Carlo}

\section{Alpha-Beta: Cowthello Heuristik vs Monte Carlo}

\section{Monte Carlo vs Alpha-Beta: Nijssen 2007 Heuristik}

\section{Monte Carlo vs Alpha-Beta: Cowthello Heuristik}
