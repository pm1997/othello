\chapter{Evaluierung}
Ziel dieses Kapitel ist es die im vorherigen Kapitel vorgestellte Implementierung zu testen. Dabei ergeben sich im wesentlichen zwei Testaspekte: Zum einen die vorgestellten Agenten und zum anderen die Bedeutung der in Kapitel \ref{impl:stored-mc} eingeführten Feldkategorien.
\paragraph{}
Die Evaluierung der einzelnen Agenten erfolgt dabei im wesentlichen dadurch die Agenten gegeneinander spielen zu lassen. Mittels einer genügend großen Anzahl von Spielen lässt sich darart ermitteln welcher der jeweils verwendeten Agenten im Mittel die meisten Spiele gewinnt und damit besser ist.
\\Die Bedeutung der Feldkategorien wird Anhand der Gewinnwahrscheinlichkeit einer Spielkategorie über den Spielfortschritt untersucht.
\section{Evaluierung der einzelnen Agenten}
\label{cpt:eval-agents}
Nun gilt es die in Kapitel \ref{implementation} beschriebenen Agenten zu evaluieren. In Ermangelung eines Othello-Spielers, der über ein entsprechend gute Spielfähigkeiten verfügt, so dass er zu einem aussagekräftigen Vergleich herangezogen werden könnte, werden die einzelnen Agenten untereinander verglichen. Die einstellbaren Parameter wurden dabei so gewählt, dass der Agent im Laufe eines Spiels ungefähr 5 Minuten zum Treffen seiner Entscheidung benötigt. Auf die genauen Werte der Parameter soll hier nicht näher eingegangen werden. Aus Gründen der Nachvollziehbarkeit finden sie sich in den Anschnitten \nameref{eval:agents:params:subsec-mc} bzw. \nameref{eval:agents:params:subsec-ab}
\\Bei der Bestimmung der Parameter sich gezeigt, dass die beim Agenten \mxZitat{Alpha-Beta Pruning} gewählte Heuristik die Gewinnchance des Agenten wesentlich beeinflusst. Aus diesem Grund wird der \mxZitat{Alpha-Beta Pruning}-Agent mit allen zur Verfügung stehenden Heuristiken seperat betrachtet. Die sich daraus Ergebenden Vergleiche sind in Tabelle \ref{tbl:cmp-agents} dargestellt. Der Agent \mxZitat{Alpha-Beta Pruning} wird dabei durch \mxZitat{AB} abgekürzt.
\paragraph{Vergleich mit dem Agent \mxZitat{Random}}
Grundsätzlich gilt, dass der durch einen Agenten zur Auswahl von Spielzügen benötigte Rechenaufwand nur dann gerechtfertigt ist, wenn sich dieser in irgendeinen Vorteil bietet, also besser spielt als ein Agent der beliebige Spielzüge durchführt. Aus diesem Grund werden alle Agenten zunächst mit dem \mxZitat{Random}-Agenten verglichen. Daraus ergeben sich zunächst die Vergleiche 1 bis 5.
\\Da ein Agent möglicherweise über bessere Gewinnchancen verfügt, wenn er als ein bestimmter Spieler auftritt gilt es außerdem zu Prüfen wie sich die Agenten verhalten, wenn sie auf der anderen Position verwendet werden. Daraus ergeben sich die Vergleiche 6 bis 10. 

\paragraph{Vergleich der Agenten \mxZitat{Alpha-Beta Pruning} und \mxZitat{Monte Carlo}}
Bisher wurden die Agenten \mxZitat{Alpha-Beta Pruning} und \mxZitat{Monte Carlo} lediglich mit dem \mxZitat{Random}-Agenten verglichen. Interessant ist daher auch die Fragestellung wie die beiden Agenten gegeneinander Spielen. Hier sei vorweggegriffen, dass Anhand der im Abschnitt \nameref{p:vgl-result} dargestellten Ergebnisse der Vergleiche 2 bis 5 bzw. 7 bis 10 festgestellt werden konnte, dass der Agent \mxZitat{Alpha-Beta Pruning} mit der Heuristik \mxZitat{???} \unsure{ermitteln} die besten Ergebnisse erzielt. Daher wird diese für den Vergleich der Agenten untereinander herangezogen. Aus den oben beschriebenen Gründen ergeben sich daraus die beiden Vergleiche 11 und 12.

\begin{table}[ht]
\begin{center}
\begin{tabular}{| c | c | c |} \hline
Vergleich & Agent 1 & Agent 2 \\ \hline
\hline
0 & Random & Random  \\ \hline
\hline
 1 & Monte Carlo                         & Random  \\ \hline
 2 & AB (Nijssen 2008 Heuristik)         & Random\\ \hline
 3 & AB (Stored Monte Carlo Heuristik)   & Random\\ \hline
 4 & AB (Cowthello Heuristik)            & Random\\ \hline
 5 & AB (mit anschließendem Monte Carlo) & Random\\ \hline
\hline
 6 & Random                              & Monte Carlo                         \\ \hline
 7 & Random                              & AB (Nijssen 2008 Heuristik)         \\ \hline
 8 & Random                              & AB (Stored Monte Carlo Heuristik)   \\ \hline
 9 & Random                              & AB (Cowthello Heuristik)            \\ \hline
10 & Random                              & AB (mit anschließendem Monte Carlo) \\ \hline
\hline
11 & AB (beste)                          & Monte Carlo                         \\ \hline
12 & Monte Carlo                         & AB (beste)                          \\ \hline
\end{tabular}
\end{center}
\caption{Durchgeführte Vergleiche}
\label{tbl:cmp-agents}
\end{table}

\paragraph{Ergebnisse der Vergleiche}
\label{p:vgl-result}
Um zum einen ein möglichst aussagekräftiges Ergebnis zu erhalten und zum Anderen die zur Durchführung der Spiele erforderliche Rechenzeit zu beschränken wurden für jeden der in Tabelle \ref{tbl:cmp-agents} angegebenen Vergleiche jeweils bis zu 1000 Spiele durchgeführt. Bei einigen Kombinationen wurden aus Gründen der erforderlichen Rechenzeit weniger als 1000 Vergleiche durchgeführt. Ist dies der Fall, so wird dies in der entsprechenden Spalte angegeben. Die Ergebnisse dieser Vergleiche finden sich in Tabelle \ref{tbl:cmp-results}:

\begin{table}[ht]
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c | c |} \hline
\multirow{3}{*}{Vgl.} & \multirow{3}{*}{Anz. Spiele} & \multicolumn{4}{|c|}{Gewonnene Spiele} & \multicolumn{2}{|c|}{$\varnothing$ Rechenzeit je Spiel [s]} \\ \cline{3-8}
                      &                              & \multicolumn{2}{|c|}{Agent 1} & \multicolumn{2}{|c|}{Agent 2} & \multirow{2}{*}{Agent 1} & \multirow{2}{*}{Agent 2} \\ \cline{3-6}
                      &                              & Anz. & Anteil [\%]            & Anz. & Anteil [\%]            &                          &                          \\ \hline
\hline
 0 & 1000 &  429 &  42,9 &  527 &  52,7 &   0,00027 &   0,00026 \\ \hline
 \hline
 1 & 1000 & 1000 & 100,0 &    0 &   0,0   & 118,21435 &   0,00235 \\ \hline
 2 & P.M. & -    & -     & -    & -     & -         & -         \\ \hline
 3 & T.M. & -    & -     & -    & -     & -         & -         \\ \hline
 4 & 1000 &  564 &  56,4 &  324 &  32,4 & 156,59706 &   0,00056 \\ \hline
 5 &  200 &  132 &  66,0 &   60 &  30,0 & 550,9348  &   0,00045 \\ \hline
 \hline
 6 & 1000 &    0 &   0,0 & 1000 & 100,0 &   0,00235 & 120,86694 \\ \hline
 7 & M.Z, & -    & -     & -    & -     & -         & -         \\ \hline
 8 & 1000 &  446 &  44,6 &  550 &  55,0 &   0,00034 & 234,01762 \\ \hline
 9 & 1000 &  289 &  28,9 &  709 &  70,9 &   0,00049 & 149,17649 \\ \hline
10 & S.K. & -    & -     & -    & -     & -         & -         \\ \hline
\hline
11 & -    & -    & -     & -    & -     & -         & -         \\ \hline
12 & -    & -    & -     & -    & -     & -         & -         \\ \hline
\end{tabular}
\end{center}
\caption{Ergebnisse der Vergleiche}
\label{tbl:cmp-results}
\end{table}
\newpage
\section{Anpassung der Parameter der verschiedenen Agenten}
In Kapitel \ref{cpt:eval-agents} bereits beschrieben, soll die Gesamtberechnungsdauer eines Agenten pro Spiel etwa 5 Minuten betragen. Dementsprechend wurden die Parameter der einzelnen Agenten so angepasst, dass sich die Berechnungsdauer meistens unterhalb dieser Zeit befindet. Aufgrund der unterschiedlichen möglichen Spielabläufe existieren eine sehr unterschiedliche Spiellänge. Es gibt sehr schnelle Spiele, welche nicht einmal 60 Züge beinhalten aber auch sehr lange Spiele, bei denen je Zug viele mögliche Zugpositionen evaluiert werden müssen. Zur Sicherstellung der Vergleichbarkeit wurde ein Surface mit einem i7 und 2,11 GHz Basisgeschwindigkeit, als Vergleichsgerät festgelegt. Aus Gründen der schnelleren Ausführung der Tests, der langen Laufzeit und der stromsparenden Berechnung wurden die Tests aus Tabelle \ref{tbl:cmp-results} auf mehreren Servern durchgeführt.
\\Nun wurden die verfügbaren Parameter der Agenten auf die o.g. Spezifikationen angepasst.
\subsection*{Parameter des \mxZitat{Monte Carlo}-Agenten}
\label{eval:agents:params:subsec-mc}
Der Monte Carlo Agent besitzt folgende Parameter (siehe Kapitel \ref{mc_params}):
\begin{itemize}
\item \code{big\_n}
\item \code{use\_start\_libs}
\item \code{preprocessor}
\item \code{preprocessor\_parameter}
\item \code{heuristic}
\item \code{use\_multiprocessing} 
\end{itemize}
Der Parameter \code{use\_multiprocessing} wird aktiviert, da es bei dem Monte Carlo Agenten nur einen negativen Effekt bis 80 Spiele (Wert des Parameters \code{big\_n}) je Zug gibt. Dieser entsteht dadurch, dass das aufteilen der zu berechnenden Spiele auf mehrere Prozessorkerne eine gewisse Zeit beansprucht. Ist die Summer dieser Zeit und die Zeit der Berechnung der Spiele größer als die Berechnungszeit der Spiele auf einem einzelnen Prozessorkern, ist dieser Parameter unwirtschaftlich. Ist \code{big\_n} größer als diese Anzahl können durch die Nutzung mehrerer Prozessorkerne mehr Spiele in fünf Minuten berechnet werden. Da dadurch die Gewinnwahrscheinlichkeit des Agenten steigt, wird der Parameter \code{use\_multiprocessing}.
\\Der Parameter \code{preprocessor} wird auf \mxZitat{None} gesetzt (deaktiviert). Durch die Nutzung eines Preprozessors wird die Anzahl der Zugmöglichkeiten je Zug verkleinert. Dadurch können ebenfalls mehr Spiele in der vorgegeben Zeit durchgeführt werden. Allerdings können dann auch Zugmöglichkeiten wegfallen, welche zu einem Sieg des Agenten geführt hätten. Deshalb wurde dieser Parameter deaktiviert, damit aus allen Zugmöglichkeiten ausgewählt werden kann.
\\Durch die Deaktivierung des Parameters \code{preprocessor}, werden automatisch die Parameter \\\code{preprocessor\_parameter} und {heuristic} deaktiviert, da diese nur im Prepozessor verwendet werden.
\\\code{use\_start\_libs} verkürzen die Berechnungsdauer der ersten Züge enorm, da die Züge aus der Starttabellen gelesen werden und nicht berechnet werden. Dadurch können mehr Spiele durchgeführt werden, ohne dass dies einen negativen Effekt auf das Spiel hat. Einerseits können die Felder, welche durch in der Eröffnungsphase gesetzt werden im weiteren Spiel noch mehrfach gedreht werden, andererseits sind keine willkürlichen Züge in der Tabelle gespeichert, sondern \mxZitat{gute} Eröffnungszüge.
\\Nachdem alle Parameter bis auf \code{big\_n} gesetzt sind, wird dieser empirisch ermittelt, indem mehrere Spiele mit unterschiedlichen \code{big\_n} gespielt werden. Aus dieser Testreihe ergab sich einen \code{big\_n} Wert von \mxZitat{2000}. Die Gesamtdauer der Spiele beträgt meistens drei bis fünf Minuten. Wird der Parameter weiter erhöht, wird die Gesamtspielzeit des Agenten von fünf Minuten überschritten.
\subsection*{Parameter des \mxZitat{Alpha-Beta Pruning}-Agenten}
\label{eval:agents:params:subsec-ab}
Das gleiche Vorgehen aus dem vorherigen Abschnitt wird nun ebenfalls auf den \mxZitat{Alpha-Beta Pruning}-Agenten angewendet.
Dieser Agent besitzt folgende Parameter:
\begin{itemize}
\item \code{\_use\_start\_libs}
\item \code{\_search\_depth}
\item \code{\_heuristic}
\item \code{\_use\_monte\_carlo}
\item \code{\_mc\_count}
\end{itemize}
\code{\_use\_start\_libs} wird immer aktiviert, da die Ausführungszeit eines Spiels merklich verkleinert wird. Je nach Spielzug des Gegners können bis zu 21 Züge aus der Datenbank  gelesen werden und müssen nicht berechnet werden.
\\\code{\_heuristic} wurde jeweils variiert, damit ein Vergleich der Heuristiken möglich ist. Bei der Verwendung einer Heuristik wurden die Parameter \code{\_use\_monte\_carlo} und \code{\_mc\_count} deaktiviert (\code{\_use\_monte\_carlo} wird auf \mxZitat{False} gesetzt). Die ermittelte Suchtiefe (\code{\_search\_depth}) beträgt \mxZitat{5}. Bei höheren Suchtiefen wird das Berechnungszeitlimit von fünf Minuten überschritten.
\vspace{0.5cm}
\\Neben Heuristiken kann die Alpha-Beta Suche auch Monte Carlo zur Ermittlung des Spielzustandswertes nach der Alpha-Beta Suche genutzt werden.
\\\code{\_use\_monte\_carlo} wird dazu aktiviert (Wert auf \mxZitat{True} gesetzt). \code{\_mc\_count} gibt die Anzahl der durchgeführten Monte Carlo Spiele je Blattknoten an. Dieser Parameter wurde auf \mxZitat{10} gesetzt, da die Alpha-Beta Suche ohne eine anschließende Aktion relativ lange dauert. Deshalb können in den Blattknoten im Vergleich zum reinen Monte Carlo Agenten nicht annähernd so viele Spiele durchgeführt werden. 
\\\code{\_search\_depth} wurde durch empirisches Testen der Laufzeit auf \mxZitat{2} festgelegt.
\section{Evaluierung der Bedeutung verschiedener Feldkategorien}
Einleitung
\subsection{Methode und Ergebnisse}
\paragraph{Methode}
Für die Beurteilung der Bedeutung einzelner Feldkategorien wurde die, für die im Kapitel \ref{cpt:eval-agents} durchgeführten Vergleiche, mit der \mxZitat{Stored Monte Carlo Heuristik} aufgebaute Datenbank, verwendet.\improvement{entschachteln}
\\Diese Datenbank wurde, wie in Kapitel \ref{heuristic} erläutert, durch das Spielen von Partien zwischen zwei \mxZitat{Random}-Agenten aufgebaut. Im vorliegenden Fall wurden $140.000$ Spiele simuliert. Nun kann für jede Zugnummer und für jeden Spieler die Gewinnwahrscheinlichkeit für das Spielen einer Feldkategorie berechnet werden, indem für jede Kategorie die Anzahl der Spiele, die nach Spielen eines Feldes dieser Kategorie gewonnen wurde, durch die Anzahl der Spiele, die insgesamt für die jeweilige Kategorie gespielt wurden, dividiert wird. Um eine Division durch $0$ zu vermeiden, wird die berechnete Gewinnwahrscheinlichkeit auf $0$ gesetzt sofern bei der jeweiligen Zugnummer nie eine derartige Feldkategorie gespielt wurde. Aufgrund der großen Anzahl von zufällig gespielten Spielen ist in diesem Fall davon auszugehen, dass es zu der jeweiligen Zugnummer keine Möglichkeit gibt eine derartige Feldkategorie zu spielen. 
\\Insgesamt ergibt sich damit pro Spieler eine Relation $\lbrace0, ..., 59\rbrace\times\lbrace0, ..., 8\rbrace\mapsto\lbrack0,1\rbrack$, die für die Zugnummer und für die Feldkategorie jeweils die Wahrscheinlichkeit angibt.
  
\paragraph{Ergebnisse}
Um die große Anzahl von $60\ \mathtt{Zugnummern} * 9\ \mathtt{Zugkategorien} = 540$ Wahrscheinlichkeitswerten pro Spieler übersichtlich darstellen zu können, werden diese grafisch aufbereitet. Da hierfür ausschließlich zweidimensionale Diagramme zum Einsatz kommen, sollen besteht die Möglichkeit hier nach der Zugnummer oder der Feldkategorie zu schneiden. Die Abbildungen \ref{fig:win-pro-fc-0} bis \ref{fig:win-pro-fc-8} im Anhang geben die Gewinnwahrscheinlichkeiten für den Schnitt nach der Feldkategorie an.
\\Die Abbildungen \ref{fig:win-pro-turn-0} bis \ref{fig:win-pro-turn-59} im Anhang geben die Gewinnwahrscheinlichkeiten für den Schnitt nach der Zugnummer an. Da aus Platzgründen nicht alle 60 der sich daraus ergebenden Abbildungen abgedruckt werden sollen, wurde dabei die willkürlich gewählte Schrittweite von 5 Zugnummern gewählt. Die Situation für den Zug 59 wird trotzdem angegeben.

\subsection{Besprechung der Ergebnisse}
Bei der Betrachtung der Diagramme fallen einige Aspekte sofort auf:
\begin{enumerate}
\item Spieler Zwei besitzt fast durchgehend eine höhere Gewinnwahrscheinlichkeit als Spieler 1
\\Dies liegt vermutlich darin begründet, dass Spieler 1 das Spiel eröffnet. Fasst man zwei aufeinanderfolgende Züge nun als Halbzüge eines kompletten Spielzuges auf, so kann Spieler 2 immer direkt auf den Zug des Spieler 1 reagieren.
\item Einige Feldkategorien spielen erst nach einer gewissen Zugnummer eine Rolle
\\Dies liegt darin begründet, dass ein Spielstein nur neben ein bereits besetztes Feld gelegt werden darf. Zu Beginn des Spiels sind jedoch nur die vier Steine in der Mitte des Spielfeldes gesetzt. Entsprechend dauert es einige Züge bis gewisse Feldkategorien wie bspw. die Eckfelder überhaupt erreicht werden können.
\item Die Gewinnwahrscheinlichkeit für einen einzelnen Spieler schlägt zwischen zwei aufeinanderfolgenden Zugnummern sehr stark aus. Bei der darauf folgenden Zugnummer erreicht sie jedoch wieder das ursprüngliche Niveau.
\\Üblicherweise wechseln sich die Spieler mit ihren Zügen ab. Demnach würden die Spieler bei jeder zweiten Zugnummer gar keinen Zug durchführen können, da sie nicht an der Reihe sind. Die Spieler spielen zufällig, d.h. sie spielen auch Züge, in welchen sie verlieren. Außerdem gruppieren die Feldkategorien mehrere Felder miteinander. Dadurch kann es vorkommen, dass einzelne Züge sich gegenseitig ausgleichen oder verstärken.
\\Der Spieler 2 kann in seinem letzten Zug noch viele Steine umdrehen und das Spiel wenden. Der vorletzte Zug kann zwar ebenfalls viele Steine wenden, muss aber so gewählt werden, dass der letzte Zug nicht mehr Steine wendet, als durch den vorletzten Zug \mxZitat{gewonnene} Steine erzielt wurden. Dadurch ist die Gewinnwahrscheinlichkeit des zweiten Spielers im letzten Zug höher als die des ersten Spielers. Umgekehrt gilt aber ebenfalls, dass die Gewinnwahrscheinlichkeit des ersten Spielers im vorletzten Zug höher ist, als die des zweiten Spielers.
\\Wendet man diese Regel auf die vorangegangenen Züge an, ergibt sich das deutlich sichtbare Zick-Zack Muster, welches sich über den Verlauf des Spiels sich etwa 50 Prozent annähert.
\\Über viele Spiele verteilt ergeben sich daraus die beschriebenen Schwankungen.
\end{enumerate}
