\chapter{Implementierung der KI}
\label{implementation}
In den folgenden Unterkapiteln  werden verschiedene Spielalgorithmen vorgestellt und implementiert. Anschließend werden diese verbessert und auch unter Berücksichtigung des Laufzeitverhaltens analysiert.
\\Zunächst wird aber die grundsätzliche Programmstruktur erläutert und das Spielgerüst implementiert, damit unterschiedliche Spieler es ausführen können.
\section{Grundlegende Spiel-Elemente}
Die Python Implementierung befindet sich im Verzeichnis \mxZitat{python} des zu diesem Projekt gehörenden Git Repository. Um das Spiel zur Ausführung zu bringen werden die Pakete \mxZitat{numpy} sowie \mxZitat{pandas} benötigt. Sind diese Abhängigkeiten vorhanden, kann das Spiel durch das Ausführen des Kommandos \code{python main-game} gestartet werden.
\\Die einzelnen Komponenten wurden unter thematischen Gesichtspunkten in verschiedenen Dateien organisiert. Nachfolgend wird auf die einzelnen Dateien und deren Funktion kurz eingegangen.
\subsection{Der Spielablauf}
In \mxZitat{main-game.py} wird das Rahmenprogramm gestartet. In diesem werden zunächst die Spieler festgelegt. Anschließend wird ein Spiel erstellt, initialisiert und das Spielbrett ausgegeben ( siehe Listing \ref{lst:lst-main-game} Z. 2-4). Die Methode \code{game\_is\_over} gibt bei Spielende \code{True}, ansonsten \code{False} zurück. In der Schleife von Zeile 5 bis Zeile 11 wird der Agent des aktuelle Spielers ermittelt (Z. 6f.). Für diesen wird die Funktion \code{get\_move} aufgerufen. Diese gibt den nach der Strategie des jeweiligen Agenten besten Spielzug zurück. Je nach Spielagent werden unterschiedliche Algorithmen zur Ermittlung dieses Zuges verwendet. Dieser Zug wird gespielt und auf das Spielbrett angewendet (Z. 9). Abschließend wird das aktualisierte Spielbrett und der zuletzt durchgeführte Zug ausgegeben (Z. 10f.). Die Schleife wird bis zum Spielende wiederholt. Danach wird der Gewinner und die gesamte Spieldauer ermittelt und ausgegeben (Z. 12-15).
\newpage
\begin{lstlisting}[caption = {Spielablauf in \mxZitat{main-game.py}}, language = python, captionpos = t , numbers=left, label={lst:lst-main-game}]
    players = {PLAYER_ONE: player_one, PLAYER_TWO: player_two}
    game = Othello()
    game.init_game()
    game.print_board()
    while not game.game_is_over():
        current_player = game.get_current_player()
        player_object = players[current_player]
        move = player_object.get_move(game)
        game.play_position(move)
        game.print_board()
        print(f"Played position: ({COLUMN_NAMES[move[1]]}{move[0] + 1})")
    duration = time.time() - start
    print("Game is over")
    print(f"Total duration: {duration} seconds")
    print(f"Winner is {PRINT_SYMBOLS[game.get_winner()]}")
\end{lstlisting}
\subsection{Die Klasse \mxZitat{Othello}}
\label{ot1}
Die Klasse \mxZitat{Othello} modelliert einen Spielzustand und enthält die Grundlegende Spiellogik wie bspw. die Berechnung erlaubter Züge. Nachfolgend wird auf die Art der Speicherung eines Spielzustandes und auf die wichtigsten Funktionen dieser Klasse eingegangen.
\paragraph{Klassenvariablen}
In Listing \ref{lst:class-vars-othello} sind alle Klassenvariablen, sowie deren Initialisierungswerte angegeben.
\begin{enumerate}
\item \code{\_board}: Bei \code{\_board} handelt es sich um eine Liste von Listen, zur Modellierung der zweidimensionalen Struktur des Spielbretts. Initialisiert wird das Spielbrett in seinem Leerzustand. Daher wird zu Beginn jedes Feld auf \code{0} zur Repräsentation des leeren Feldes gesetzt.
\item \code{\_current\_player}: Speichert den Spieler, der im modellierten Spielzustand an der Reihe ist.
\item \code{\_last\_turn\_passed} wird verwendet um zu speichern ob der vorherige Spieler  passen musste. Dadurch kann das Spiel sobald zwei Spieler unmittelbar nacheinander passen müssen beendet werden.
\item \code{\_game\_is\_over} wird auf \code{True} gesetzt sobald das Spiel beendet ist
\item \code{\_fringe}: In \code{\_fringe} werden alle Felder des Spielfeldes gespeichert die in eine Richtung unmittelbar neben einem bereits besetzten Feld liegen. Durch die Mitführung dieser Information muss zur Berechnung der erlaubten Züge nicht jedes mal über das Spielfeld iteriert werden um zunächst die infrage kommenden Felder zu ermitteln.
\item \code{\_turning\_stones}: Enthält als Schlüssel alle erlaubten Züge und als Wert jeweils eine Liste jener Spielsteine die durch ausführen des Zuges umgedreht werden. Da zur Ermittlung der erlaubten Züge diese Information bereits berechnet werden muss, wird sie in Form des Dictionarys vorgehalten um diese an anderer Stelle nicht erneut berechnen zu müssen.
\item \code{\_taken\_moves}: Speichert alle ausgeführten Züge die erforderlich waren um den modellierten Spielzustand zu erreichen, da einige Algorithmen diese Information benötigen.
\item \code{\_turn\_nr}: Speichert die Nummer des aktuellen Spielzuges, da die verwendete Strategie bei einigen Algorithmen davon abhängt, wie weit das Spiel schon fortgeschritten ist.
\end{enumerate}
\begin{lstlisting}[caption = {Klassenvariablen der Klasse \mxZitat{Othello}}, language = python, captionpos = t , numbers=left, label={lst:class-vars-othello}]
    _board = [[0 for _ in range(8)] for _ in range(8)]
    _current_player = None
 
    _last_turn_passed = False
    _game_is_over = False

    _fringe = set()
    _turning_stones = dict()
    
    _taken_moves = dict()
    _turn_nr = 0
\end{lstlisting}
\paragraph{Die Funktion \code{\_compute\_available\_moves}}
 ist in Listing \ref{lst:fct-compute-available-moves} angegeben und wird verwendet um die Inhalte des Dictionaries \code{\_turning\_stones} zu berechnern.
\\Da beiden Spielern in der Regel nicht die gleichen Züge zur Verfügung stehen muss zunaächst der vorherige Inhalt von \code{\_turning\_stones} gelöscht werden. Dies geschieht in Zeile 2, indem die Datenstruktur neu initialisiert wird.
\\In Zeile 3 wird eine lokale Referenz des zur Darstellung eines durch den aktuellen Spieler besetzen Feldes verwendeten Symbols erzeugt.
\\Mit der in Zeile 4 beginnenden Schleife wird über alle in Frage kommenden Züge in der Menge \code{\_fringe} iteriert um zu ermitteln, ob dieser Zug erlaubt wäre.
\\Dazu wird zunächst eine lokale Menge initialisiert um die durch spielen dieser Position gedrehten Steine zu speichern (Zeile 5).
\\Nun muss ausgehend von der derzeit betrachteten Position ermittelt werden, ob in irgendeine Richtung Spielsteine gedreht werden würden. Dies erfolgt durch die in Zeile 6 beginnende Schleife.
\\Dazu wird zunächst das nächste Feld in diese Richtung unter Verwendung einer Hilfsfunktion ermittelt (Zeile 7) und anschließend eine weitere termporäre Menge der in dieser Richtung gedrehten Steine initialisiert (Zeile 8)
\\Die entsprechende Richtung muss nun solange weiter verfolgt werden, wie ein weiterer Nachbar in diese Richtung vorhanden ist. Dies geschieht durch die in Zeile 9 beginnedne Schleife.
\\Da in den nachfolgenden Schritten ermittelt werden muss, welcher Spieler das derzeit betrachtete Feld besetzt hat, werden die Indizes der derzeitigen  ausgepackt (Zeile 10) und dann verwendet um zu ermitteln welchen Wert das Feld detzeit hat (Zeile 11).
\\Nun gibt es drei mögliche Fälle:
\begin{enumerate}
\setcounter{enumi}{0}
\item Es befindet sich kein Stein auf dem derzeit betrachteten Feld. In diesem Fall wird die Abfrage in Zeile 12 positiv ausgewertet und diese Richtung muss nicht weiter verfolgt werden. Entsprechend wird die while-Schleife in Zeile 13 abgebrochen.
\item Das derzeit betrachtete Feld wird durch den anderen Spieler besetzt. In diesem Fall ist die Abfrage in Zeile 14 positiv. Da der Stein ggf. umgedreht werden würde, wird die aktuelle Position gespeichert (Zeile 15)
\item Das derzeit betrachtete Feld wird durch den Spieler selbst besetzt. In diesem Fall wird die Abfrage in Zeile 16 positiv ausgewertet. Nun werden alle Steine zwischen der Ausgangsposition und der derzeitigen gedreht. Daher wird die Menge der durch diesen Zug gedrehten Steine mit der in diese Richtung befindlichen Steine vereinigt (Zeile 17) und die Schleife verlassen (Zeile 18).
\end{enumerate}
In Zeile 19 wird das nächste Feld in diese Richtung berechnet.
\\Gemäß der Regeln muss durch jeden Zug mindestens ein Stein gedreht werden. Aus diesem Grund wird nun ermittelt, ob dies bei diesem Zug gegeben wäre (Zeile 20). Ist dies der Fall, so werden die gedrehten Steine für diesen Zug in \code{\_stones\_to\_turn} gespeichert (Zeile 21).
\\Hat ein Spieler nun keine Möglichkeiten einen Zug durchzuführen, so sind in \code{\_stones\_to\_turn} keine Züge enthalten. Dieser Fall muss besonders behandelt werden. Tritt er ein, so wird die Abfrage in Zeile 22 positiv ausgewertet.
\\In diesem Fall muss nochmal unterschieden werden, ob der vorherige Spieler ebenfalls keinen Zug zur Auswahl hatte (Zeile 23).
\\Falls ja so ist das Spiel zu ende. Dies wird durch das Setzen von \code{\_game\_is\_over} gespeichert (Zeile 24).
\\Falls nein (Zeile 25), so wird gespeichert, dass der Spieler passen musste (Zeile 26) und der nächste Zug vorbereitet (Zeile 27).
\\Hat der Spieler hingegen eine Zugmöglichkeit (Zeile 28) so hat er aus Sicht des folgenden Zuges nicht passen müssen. Entsprechend wird \code{\_last\_turn\_passed} wieder auf \code{False} gesetzt. 
\begin{lstlisting}[caption = {Die Funktion \code{\_compute\_available\_moves}}, language = python, captionpos = t , numbers=left, label={lst:fct-compute-available-moves}]
    def _compute_available_moves(self):
        self._turning_stones = dict()
        own_symbol = self._current_player
        for current_position in self._fringe:
            position_turns = set()
            for direction in DIRECTIONS:
                next_step = Othello._next_step(current_position, direction)
                this_direction = set()
                while next_step is not None:
                    (current_x, current_y) = next_step
                    current_value = self._board[current_x][current_y]
                    if current_value == EMPTY_CELL:
                        break
                    elif current_value != own_symbol:
                        this_direction.add(next_step)
                    elif current_value == own_symbol:
                        position_turns = position_turns | this_direction
                        break
                    next_step = Othello._next_step(next_step, direction)
            if len(position_turns) > 0:
                self._turning_stones[current_position] = position_turns
        if len(self._turning_stones) == 0:
            if self._last_turn_passed:
                self._game_is_over = True
            else:
                self._last_turn_passed = True
                self._prepare_next_turn()
        else:
            self._last_turn_passed = False
\end{lstlisting}
\paragraph{Weitere Funktionen der Klasse \mxZitat{Othello}}
Die Klasse \mxZitat{Othello} enthält weitere Funktionen, auf welche hier jedoch nicht im Detail eingegangen werden soll. Dennoch sei hier jeweils kurz deren Verwendungszweck der wichtigsten Funktionen genannt:
\begin{enumerate}
\item \code{play\_position} verändert den Spielzustand dahingehend, dass der übergebene Zug, sofern er erlaubt ist, ausgeführt wird, die entsprechenden Steine des Gegners gedreht und dessen Zug vorbereitet wird. Dabei wird auch die \code{\_fringe} entsprechend aktualisiert.
\item \code{set\_available\_moves} verändert \code{\_stones\_to\_turn} dahingehend, dass nur noch übergebene Positionen enthalten sind. Kann damit zum Filtern der erlaubten Züge verwendet werden.
\item \code{get\_available\_moves}: Gibt die erlaubten Züge zur Verwendung in den Spieler-\\implementierungen zurück
\item \code{other\_player}: Gibt das Symbol des anderen Spielers zurück
\item \code{utility}: Gibt gemäß der Definition eines Spiels 0, 1 oder -1 zurück.
\item \code{get\_winner}: Ermittelt den Gewinner des Spiels und gibt ihn zurück.
\item \code{get\_statistics}: Gibt die Anzahl der Felder pro Spieler zurück.
\item \code{get\_current\_player}: Gibt den derzeitigen Spieler zurück.
\item \code{game\_is\_over}: Gibt zurück ob das Spiel bereits zu Ende ist.
\item \code{init\_game}: Bereitet den Start eines Spiels vor indem die initial besetzen Felder entsprechen gesetzt werden. Der beginnende Spieler festgelegt und die  \code{\_fringe} vorbereitet, sowie \code{\_stones\_to\_turn} für den ersten Zug berechnet.
\end{enumerate}
\subsection{Die übrigen Komponenten}
Neben den zuvor detailliert besprochenen finden in der Implementierung noch die folgenden Komponenten Anwendung: 
\begin{enumerate}
\item Konstanten in der Datei \code{constants.py}. Durch die Verwendung von Konstanten bspw. zur Symbolisierung von welchen Spieler ein Feld besetzt ist, wird einerseits von konkreten Werten abstrahiert und diese sind, sofern erforderlich einfach austauschbar. Andererseits wird eine gewisse Konsistenz, bspw. für Mapping-Funktionen zur Ausgabe, über das ganze Programm hinweg erreicht.
\item Hilfsfunktionen in der Datei \code{util.py} werden dazu genutzt Werte vom Benutzer abzufragen.
\end{enumerate}
\section{Heuristiken}
\label{heuristic}
Wie im Abschnitt \ref{Heuristiken} besprochen werden für einige Algorithmen Funktionen zur Approximation des Wertes eines Spielzustandes benötigt. Im Rahmen dieser Arbeit wurden die folgenden Heuristiken implementiert:
\begin{enumerate}
\item Nijssen 2007 Heuristik
\item Stored Monte-Carlo-Heuristik
\item Cowthello Heuristik
\end{enumerate}
Die Implementierung aller Heuristiken befinden sich in der Datei \code{heuristics.py}
\subsection{Nijssen 2007 Heuristik}
Die \mxZitat{Nijssen 2007 Heuristik} wurde aus \cite{nijssen_2007} übernommen. Ihr liegt die im Kapitel \ref{othello-chapter} erläuterte Idee zugrunde, die einzelnen Spielfelder in Kategorien einzuteilen und jeder Kategorie einen speziellen Wert zuzuweisen. Die Bewertung des Spielzustandes $s$ aus Sicht eines Spielers $\mathtt{player}$ ergibt sich dann nach der folgenden Formel: $\mathtt{heuristic}(\mathtt{player}, S) = \sum\limits_{f \in \mathtt{domain}(\mathtt{F}(s))}  w_{f} * b_{f}$ wobei $F(s)$ eine Funktion ist, die für das Spielfeld des Zustands $s$ eine Relation zurückgibt die für jedes Feld angibt durch welchen Spieler es besetzt ist oder ob es leer ist, $w_{f}$ für das dem Feld zugeordnete Gewicht und $b_{f} = \begin{cases} 1 \mathtt{,\ wenn\ F}(s)[f] = \mathtt{player} \\ -1 \mathtt{,\ wenn\ F}(s)[f] = \mathtt{other(player)} \\ 0 \mathtt{,\ sonst} \end{cases}$
\\Für die Gewichte $b_{f}$ der im Kapitel \ref{othello-chapter} eingeführten Kategorien vergibt Nijssen die folgenden Gewichte:
\begin{enumerate}
\item \code{Eck-Felder}: $+5$
\item \code{X-Felder}: $-2$
\item \code{C-Felder}: $-1$
\item \code{Zentral-Felder}: $+2$
\item \code{Andere-Felder}: $+1$
\end{enumerate}
\subsection{Stored Monte-Carlo-Heuristik}
\label{impl:stored-mc}
Die \mxZitat{Stored Monte-Carlo-Heuristik} verwendet eine Datenbank. In dieser Datenbank werden die Anzahl der gespielten und gewonnenen Spielzüge gespeichert. Diese wird in den Unterabschnitten \nameref{para:db} und \nameref{para:train1} erklärt. Darauf aufbauend wird die Funktionsweise der Heuristik in dem Abschnitt \nameref{para:heuristic1} erläutert.
\paragraph{Datenbank}
\label{para:db}
Die Datenbank speichert zu jeder Zugnummer die Gewinnwahrscheinlichkeiten der Spieler bei der Verwendung der Feldkategorien zu einer bestimmten Zugnummer. Sie ist in der Datei \code{database\_moves.csv} im CSV-Format gespeichert. Es existieren zehn Feldkategorien. 
Das Spielfeld ist symmetrisch zum Mittelpunkt aufgebaut. Dies bedeutet, dass Züge, welche symmetrisch zu anderen Zügen sind, als ein Zug angesehen werden können. In Abbildung \ref{fig:sym1} sind die symmetrischen Felder des Othello-Spielbrettes farblich hervorgehoben. Die unterschiedlichen Farben stellen die unterschiedlichen Feldkategorien dar. Diese sind von Null bis Acht durchnummeriert. Das Zentrum ist mit \mxZitat{X} markiert. Da das Zentrum bei Spielstart schon besetzt ist, wird diese Feldkategorie nicht in der Datenbank gespeichert. Die restlichen neun Kategorien sind als Spalten in der Datenbank abgebildet.
\\\mxPicture{10cm}{symmetrie}{Symmetrie des Spielfeldes}{Symmetrie des Spielfeldes}{fig:sym1}{}
\\Die Datenbank besteht aus 60 Zeilen und neun Spalten. Die neun Spalten stellen o.g. Feldkategorien ( \mxZitat{0} bis \mxZitat{8}) dar. Die c-te Spalte in der n-ten Zeile stellt die Gewinnwahrscheinlichkeiten des Spieles dar, wenn im n-ten Spielzug ein Feld der c-ten Feldkategorie gespielt wird. 
\\Die mathematische Formel dazu lautet:
$database_{n,c} = P( \mathtt{win} | \mathtt{move}(n) \in c)$, wobei gilt:
\begin{itemize}
\item $\mathtt{move}(n)$ = Feld des n-ten Spielzuges
\item $\mathtt{c} \in \{\mathtt{Feldkategorie} -\ '\mathtt{X}'\ \}$ : $c$ ist eine Feldkategorie außer das Zentrum (\mxZitat{X})
\end{itemize}
Jede Zelle in dieser Tabelle enthält ein Tripel der Form \\$( \mathtt{won\_games\_player\_1}, \mathtt{won\_games\_player\_2}, \mathtt{total\_played\_games})$. 
\\Die erste Komponente stellt die Anzahl der gewonnen Spiele des ersten Spielers dar, die zweite Komponente speichert die Anzahl der Spiele, welche der zweite Spieler gewonnen hat und die dritte Komponente gibt die Gesamtanzahl der gespielten Spiele dieser Spielkategorie an. Die genaue Funktionsweise wird in Kapitel \nameref{para:train1} erklärt.
\\Zwischen den drei Komponenten gibt es folgenden mathematischen Zusammenhang: 
\\$\mathtt{won\_games\_player\_1} + \mathtt{won\_games\_player\_2} \le \mathtt{total\_played\_games}$
\\Durch unentschiedene Spiele kann die Gesamtanzahl der Spiele größer als die Summe der gewonnen Spiele der zwei Spieler sein.
In Abbildung \ref{fig:db1} ist der Initialzustand der Datenbank dargestellt (vgl. auch Abbildung \ref{fig:sym1} bzgl. der Feldkategorien). Die Startwerte der Tupel sind jeweils \mxZitat{(0, 0, 0)}, da initial noch keine Spiele gespeichert sind.
\\\mxPicture{15cm}{db2}{Ausschnitt des Initialzustandes der Datenbank}{Ausschnitt des Initialzustandes der Datenbank}{fig:db1}{}

\paragraph{Befüllen der Datenbank}
\label{para:train1}
Nachdem die Datenbank im vorherigen Abschnitt initialisiert erstellt wurde, wird diese nun mit Spieldaten aus zufällig gespielten Spielen befüllt. In Listing \ref{lst:train1} ist das Spielen eines zufälligen Spieles und den Aufruf der Funktion \code{update\_fields\_stats\_for\_single\_game} abgebildet. Zunächst wird ein Othello-Spiel initialisiert (Z. 1f.). Durch die Nutzung des \mxZitat{Random}-Agenten wird ein komplettes Spiel durchgeführt (Z. 3f.). Anschließend wird der Gewinner ermittelt (Z. 5) und die Zugreihenfolge ermittelt (Z. 6). Die Funktion \code{update\_fields\_stats\_for\_single\_game} verwendet diese beiden Parameter um die Datenbank zu aktualisieren. Die Funktion wird in Listing \ref{lst:train2} abgebildet.

\begin{lstlisting}[caption = {Befüllen der Datenbank 1}, language = python, captionpos = t , numbers=left, label={lst:train1}]
g = Othello()
g.init_game()
while not g.game_is_over():
	g.play_position(Random.get_move(g))
winner = g.get_winner()
moves = g.get_taken_mv()
self.update_fields_stats_for_single_game(moves, winner)
\end{lstlisting}
In der Funktion \code{update\_fields\_stats\_for\_single\_game} (Listing \ref{lst:train2} Z. 9-12) wird die Liste der Züge in einzelne Züge aufgeteilt (Z. 10), welche anschließend jeweils eine Spalte in einer Datenbankzeile aktualisieren. Dazu werden die Züge, beispielsweise \mxZitat{a1}, in Zeile 11 in eine Feldkategorie umgerechnet (im Beispiel \mxZitat{0}) und ebenfalls der Methode \code{update\_field\_stat} übergeben.
\\Diese Methode liest die Werte der durch Zugnummer und Feldkategorie festgelegte Zelle aus (Z.2). Je nachdem, welcher Spieler dieses Spiel gewonnen hat, wird die Zahl der gewonnenen Spiele des ersten, zweiten oder keinem Spieler um eins erhöht (Z. 3-6). Abschließend wird die Zahl der insgesamt durchgeführten Spiele inkrementiert (Z.7 dritte Komponente) und in die Datenbank zurückgeschrieben (Z.7).
\\Die Datenbank wurde mit 140.000 Spielen trainiert, um statistische Abweichungen zu minimieren. Hierbei wirkt das Gesetz der großen Zahlen, das besagt, dass sich die Wahrscheinlichkeiten eines Ereignisses bei sehr vielen Wiederholungen dem Erwartungswert annähert.
\\Zur Auswertung der Datenbank wurde die Klasse \code{Analyse} in der Datei \code{analyse\_database.py} erstellt. Diese liest die Datenbank aus und liefert eine farbige Ansicht der Gewinnwahrscheinlichkeiten eines Spielers jeweils pro Zug auf dem Terminal. Neben dem dargestellten Spielbrett wird auch das Minimum, das Maximum, der Durchschnittswert und die Standardabweichung des dargestellten Spielbrettes berechnet.
\newpage
\begin{lstlisting}[caption = {Befüllen der Datenbank 2}, language = python, captionpos = t , numbers=left, label={lst:train2}]
	def update_field_stat(self, turn_nr, field_type, winner):
		(won_games_pl1, won_games_pl2, total_games_played) = self._data[turn_nr][field_type]
		if winner == PLAYER_ONE:
			won_games_pl1 += 1
		elif winner == PLAYER_TWO:
			won_games_pl2 += 1
		self._data[turn_nr][field_type] = (won_games_pl1, won_games_pl2, total_games_played + 1)

	def update_fields_stats_for_single_game(self, moves, winner):
		for turn_nr in range(len(moves)):
			position = self.translate_position_to_database(moves[turn_nr])
			self.update_field_stat(turn_nr, position, winner)
\end{lstlisting}

\paragraph{Heuristik}
\label{para:heuristic1}
Mithilfe der o.g. Datenbank wird eine Heuristik implementiert. Die Methode \code{heuristic} ist in Listing \ref{lst:heuristic2} abgebildet. Diese ermittelt die verfügbaren Zugmöglichkeiten und die aktuelle Zugnummer (Z. 2f.). Für jede Zugmöglichkeit wird die Gewinnwahrscheinlichkeit für den übergebenen Spieler in ein Dictionary gespeichert (Z. 6f.). Aus diesem Dictionary wird die höchste Wahrscheinlichkeit ermittelt und zurückgegeben (Z. 9f.).
\begin{lstlisting}[caption = {Stored Monte-Carlo-Heuristik Funktion}, language = python, captionpos = t , numbers=left, label={lst:heuristic2}]
def heuristic(current_player, game_state: Othello):
	moves = game_state.get_available_moves()
	turn_nr = game_state.get_turn_nr()
	move_probability = dict()

	for move in moves:
		move_probability[move] = database.db.get_likelihood(move, turn_nr, current_player)

	selected_move = max(move_probability.items(), key=operator.itemgetter(1))[0]
 	return move_probability[selected_move]
\end{lstlisting}

\subsection{Cowthello Heuristik}
Die \mxZitat{Cowthello Heuristik} wurde aus \cite{cow1} übernommen. Ihr liegt ebenfalls der in Kapitel \ref{othello-chapter} erläuterte Idee zugrunde, die einzelnen Spielfelder in Kategorien einzuteilen und jeder Kategorie einen speziellen Wert zuzuweisen. Die Heuristik unterscheidet sich von der \mxZitat{Nijssen 2007 Heuristik} nur in der genaueren Definition der Feldkategorien und unterschiedliche Gewichtungen dieser Felder.
Die Gewichte der einzelnen Felder sind in Abbildung dargestellt. Die Unterschiede zur \mxZitat{Nijssen 2007 Heuristik} bestehen in der detaillierteren Gewichtung beispielsweise der Zentralfelder (\mxZitat{1}, \mxZitat{5} oder \mxZitat{50}) im Gegensatz zu \mxZitat{2}. Die restliche Implementierung ist identisch zur \mxZitat{Nijssen 2007 Heuristik}.
\\\mxPicture{10cm}{cow1}{Gewichtung der einzelnen Spielfelder}{Gewichtung der einzelnen Spielfelder}{fig:cow1}{}

\section{Start Tabellen}
In dem Grundlagenkapitel \ref{lookup} wurden die Vor- und Nachteile von Suche vs. Nachschlagen beschrieben. In diesem Kapitel wird die Implementierung der Starttabellen mit Eröffnungszügen erklärt. Im Folgenden werden Spieltabellen und Startdatenbank synonym verwendet, da diese Tabellen als Matrix in einer Datenbank gespeichert werden.
\\Für viele Spiele, beispielsweise für Schach, existieren Starttabellen, welche die \mxZitat{besten} Eröffnungszüge speichern. Für Othello existieren zwar mehrere Spieltabellen, aber nur wenige Eröffnungsspiele. In der Implementierung werden die 77 Eröffnungszüge von Robert Gatliff \cite{open1} verwendet. Diese bestehen jeweils aus einer Zugreihenfolge, z.B. \code{c4, c3, d3, c5, b2}. 
\\Diese Züge werden im Spiel mit dem aktuellen Spielzustand verglichen. Wenn eine oder mehrere gespeicherte Züge mit dem aktuellen Spielzustand übereinstimmen, wir ein Zug aus den verfügbaren Zügen ausgewählt und gespielt. Die Funktion \code{get\_available\_moves\_of\_start\_tables} ist in Listing \ref{lst:start2} abgebildet.
\newpage
\begin{lstlisting}[caption = {Befüllen der Datenbank 2}, language = python, captionpos = t , numbers=left, label={lst:start2}]
def get_available_moves_of_start_tables(self, game: Othello):
	if len(self._start_tables) == 0:
		self._init_start_tables()
	turn_nr = game.get_turn_nr()
	available_moves = []
	taken_mv = game.get_taken_mvs_text()
	for game in self._start_tables:
		turn = 0
		for move in game:
			if turn < turn_nr:
				if taken_mv[turn] != move:
					break
			elif move != "i8" or move != "nan":  # invalid field
				available_moves.append(move)
				break
			turn += 1
	available_moves = list(dict.fromkeys(available_moves))
	if "nan" in available_moves:
		available_moves.remove("nan")
	return available_moves
\end{lstlisting}
Beim ersten Aufrufen der Starttabellen, wird die Datenbank initialisiert (Z. 2f.). Ab Zeile sieben werden alle Zeilen der Datenbank mit der aktuellen Zugreihenfolge des Spiels verglichen (Z. 9ff.). Wenn ein Zug in der bestehenden Zugreihenfolge abweichend von dem aktuellen Eintrag der Startdatenbank ist (Z. 11f.), wird der weitere Vergleich mit diesem Eintrag abgebrochen und mit dem folgenden Eintrag fortgefahren.
\\Da das Spielbrett symmetrisch zum Mittelpunkt ist, wurden die Eröffnungszüge gespiegelt. Dadurch wurde die Datenbank auf 308 Züge erweitert. Diese ist in der Datei \code{start\_moves.csv} als CSV gespeichert.
\\Die Agenten \mxZitat{Monte Carlo} und \mxZitat{Alpha-Beta Pruning} verwenden in der Standardeinstellung Starttabellen. Wenn beide Agenten gegeneinander spielen, werden die ersten Spielzüge beider Spieler sehr stark beschleunigt. Die Agenten müssen keine Züge berechnen, sondern können, bei verfügbaren Eröffnungszügen, durch das Nachschlagen in der Datenbank und die Auswahl eines Spielzuges sehr viel Spielzeit einsparen. Erst wenn die Datenbank keine passende Zugmöglichkeit mehr enthält, starten die Agenten die Berechnung des besten Zuges.
\section{Agenten}
\label{agenten}
Beim Start eines Partie stehen dem Nutzer mehrere Agenten zur Auswahl die die Rolle eines Spielers übernehmen können. Die Implementierung zu diesen Agenten befindet sich in Unterverzeichnis \code{Agents}.
\\Die folgende Agenten stehen dabei zur Auswahl:
\begin{enumerate}
\item Human
\item Random Player
\item Monte Carlo
\item Alpha-Beta Pruning
\end{enumerate}
\subsection{Human Agent}
Der \mxZitat{Human Agent} bzw. menschliche Agent stellt eine Schnittstelle die es einem menschlichen Spieler \\ermöglicht eine Spielentscheidung zu treffen. Die Implementierung findet sich in der Datei \code{human.py}
\\Neben dem Spielfeld bekommt der Nutzer dabei eine Liste aller für Ihn möglichen Züge dargestellt. Durch die Eingabe eines Zuges wird dieser im Spielmodell ausgeführt und der nächste Agent wird aufgerufen. Da das Ziel dieser Arbeit darin besteht eine künstliche Intelligenz zur Wahl der Züge zu entwickeln, soll an dieser Stelle nicht weiter auf diesen Agenten eingegangen sein.

\subsection{Random}
Die Implementierung des Agenten \mxZitat{Random} befindet sich in der Datei \code{random.py}. Dieser Agent ist die einfachste Form der im Rahmen dieser Arbeit eingesetzen Strategien einer künstlichen Intelligenz. Ihr liegt die Idee zugrunde, dass der Agent einen zufälligen Zug aus der Menge der erlaubten Züge auswählt.
\\In der mit der Arbeit entwickelten Implementierung ist dies derartig umgesetzt, dass der Agent die Liste der möglichen Züge aus dem Spielzustand abruft und einen zufälligen Index der Liste auswählt um dann den dort angegebenen Zug zu spielen.

\subsection{Monte Carlo}
Hinter diesem Agenten steht das im Kapitel \ref{mc_algo} erläuterte Prinzip, der zufällig gespielten Spiele zur Ermittlung des Spielzuges mit der höchsten Gewinnwahrscheinlichkeit. Dabei werden ausgehend von einem derzietigen Spielzustand $N$ Spiele simuliert in dem für beide Spieler der Agent \mxZitat{Random} verwendet wird. Dabei wird für den jeweils ersten simulierten Zug gespeichert wie oft dieser durchgeführt wurde und wie häufig dies in einer gewonnenen Simulation resultierte. In dem nicht simulierten Spiel wird dann jener Spielzug ausgeführt, bei dem der Quotient aus der Anzahl der nach spielen dieses Zuges gewonnen Spiele und der Anzahl der simulierten Spiele die mit diesem Zug begonnen wurden, am größten ist.
\\Nachfolgend wird dieses Prinzip anhand des Quellcodes nochmals erläutert.
\\Die Spielerklasse \mxZitat{MonteCarlo} ist in der Datei \mxZitat{python/Agents/monteCarlo.py} zu finden.
\subsubsection{Parameter}
\label{mc_params}
Das genaue Verhalten des Agenten kann durch die folgenden Paramter beeinflusst werden: 
\begin{itemize}
\item \code{big\_n}: Die Anzahl $N$ der zufällig gespielten Spiele je Zug
\item \code{use\_start\_libs}: Bool'scher Wert ob Startbibliotheken verwendet werden sollen
\item \code{preprocessor}: Der verwendete Vorverarbeiter bzw. Präprozessor. Dabei stehen die folgenden bereits im Kapitel \ref{mc_algo} besprochenen Varianten zur Auswahl:
\begin{itemize}
    \item Der feste Selektivität Präprozessor
    \item Der variable Selektivität Präprozessor
    \item Kein Präprozessor
\end{itemize}
\item \code{preprocessor\_parameter}: Parameter des verwendeten Preprozessors. Je nach Auswahl des Prä-\\prozessors steht dieser Parameter für:
\begin{itemize}
    \item Die Anzahl der Züge die durch den Präprozessor gelangen
    \item Die Prozentuale Abweichung vom Mittelwert der Wertigkeiten der Züge
\end{itemize}
\item \code{heuristic}: Eine der in  Kapitel \ref{heuristic} beschriebenen. Wird im Präprozessor zur Bewertung von Spielzuständen herangezogen.
\item \code{use\_multiprocessing}: Boolscher Wert, der angibt ob die $N$ simulierten Spiele unter Verwendung mehrerer Prozesse durchgeführt werden sollen. Bei Systemen mit mehr als einem Prozessor können damit durch Parallelisierung Geschwindigkeitsvorteile erreicht werden. 
\end{itemize}

\subsubsection{Die Präprozessoren}
Nachfolgend wird kurz auf die Implementierung der in Kapitel \ref{mc_algo} beschriebenen Präprozessoren eingegangen.
\paragraph{Der feste Selektivität Präprozessor}
Die in Listing \ref{lst:mc-prep-fixed} abgedruckte Funktion gibt die Implementierung des Präprozessors mit fester Selektivität an.
\\Die Funktion erhält einen Spielzustand \code{game\_state}, den Parameter \code{n\_s} der Anzahl $N_{s}$ der Züge, die den Präprozessor passieren und eine Heuristik \code{heuristic}, die zur Bewertung der Spielzüge herangezogen wird. In der sich über die Zeilen 3 bis 5 erstreckenden Anweisungen wird eine nach der Bewertung des einzelnen Zuges gemäß der Heuristik sortierte Liste von Zügen erstellt. In Zeile 6 werden dann nur die ersten \code{n\_s} Züge im Spielzustand \code{game\_state} gesetzt.
\begin{lstlisting}[caption = {Die Funktion \code{preprocess\_fixed\_slectivity}}, language = python, captionpos = t , numbers=left, label={lst:mc-prep-fixed}]
	@staticmethod	    
	def preprocess_fixed_selectivity(game_state: Othello, n_s, heuristic):
    heuristic_values = sorted(
        MonteCarlo.preprocess_get_heuristic_value(game_state, heuristic=heuristic).items(),
            key=operator.itemgetter(1))
    game_state.set_available_moves(heuristic_values[:n_s][0])
\end{lstlisting}
\paragraph{Der variable Selektivität Präprozessor}
In Listing \ref{lst:mc-prep-var} ist die Implementierung des Präprozessors mit variabler Selektivität angegeben.
\\Wie der Präprozessor mit fester Selektivität, erhält auch diese Funktion einen Spielzustand \code{game\_state} und eine Heuristik \code{heuristic}. Anders als bei dem oben beschriebenen Präprozessor wird hier jedoch ein Wert \code{p\_s} zur Beschreibung der maximalen prozentualen Abweichung $p_{s}$ vom Mittelwert der Wertigkeit der Züge übergeben.
\\Für die Berechnung wid zunächst der Wert der Heuristik für alle Spielzüge berechnet (Zeile 3). Daraufhin wird in der Zeile 5 der durchschnittliche Wert berechnet und mit der Anweisung in den Zeilen 6 und 7 nur jene Züge im Spielzustand gesetzt, die einen Wert größer als $p_{s}$ multipliziert mit dem durchschnittlichen Wert haben.
\newpage
\begin{lstlisting}[caption = {Die Funktion \code{preprocess\_variable\_slectivity}}, language = python, captionpos = t , numbers=left, label={lst:mc-prep-var}]
	@staticmethod
    def preprocess_variable_selectivity(game_state: Othello, p_s, heuristic):
        heuristic_value_dict = MonteCarlo.preprocess_get_heuristic_value(game_state, heuristic=heuristic)
        heuristic_values = [v for _, v in heuristic_value_dict.items()]
        average_heuristic_value = sum(heuristic_values) / len(heuristic_values)
        game_state.set_available_moves(
            [m for m, v in heuristic_value_dict.items() if v >= p_s * average_heuristic_value])
\end{lstlisting}
\subsubsection{Die Funktion \code{get\_move}}
\label{mc-getmove}
Eine Funktion \code{get\_move} wird von allen Agenten bereitgestellt und in der \code{main-game.py} zur Auswahl eines Zuges gerufen. Beschrieben wird der Zug durch ein Paar, welches die Koordinaten auf dem Spielbrett darstellt.
\\Nachfolgend wird die in Listing \ref{lst:ab1} abgedruckte Funktion diskutiert:
\vspace{0.5cm}
\\Als Parameter erhält die Fuktion den Spielzustand \code{game\state}, zu dem die Entscheidung über den nächsten Zug getroffen werden soll. In Zeile 2 wird nun überprüft, ob die Verwendung der Starttabellen aktiviert ist und zusätzlich in dem aktuellen Spiel weniger als 21 Züge gespielt wurden. Die zweite Komponente der \code{if}-Abfrage erfolgt, da die Startbibliothek maximal Strategien bis zum 20-ten Zug enthält.
\\Ist dies der Fall, so werden in Zeile 3 alle gemäß der Startbibliothek in Frage kommenden Züge ermittelt. Steht mindestens ein Zug zur Auswahl (Z. 4), so wird dieser gespielt (Z. 5). Nun werden die im vorherigen Zug ermittelten Wahrscheinlichekiten gelöscht(Z. 6) und das Symbol, welches zur Repräsentation des eigenen Spielers verwendet wird zwischengespeichert (Z.6).
\\Ist die Option zur Verwendung eines Präprozessors aktiviert, wird die Abfrage in Zeile 8 positiv ausgewertet. In diesem Fall wird der selektierte Präprozessor aufgerufen (Z. 9). Danach wird ermittelt ob die Option zur verwendung mehrer Prozesse aktiviert ist (Z. 10). Ist dies nicht der Fall, so werden \code{big\_n} zufällige Spiele gespielt (Z. 11). Die dazu aufgerufene Hilfsfunktion gibt ein Object des Typs \mxZitat{Dictionary} zurück. Dieses enthält für jeden möglichen Zug die Anzahl der gewonnen Spiele wenn dieser Zug zuerst gespielt wurde und die Gesamtanzahl von Spielen.\\
Ist die Option zur Verwendung mehrere Prozesse aktiviert, so wird der \code{else}-Zweig in den Zeilen 12 bis 20 ausgeführt:
\\Dazu wird zunächst die Anzahl der verfügbaren Prozessorkerne ermittelt (Z. 13). Im weiteren Verlauf werden entsprechend viele Prozesse verwendet. So können alle verfügbaren Prozessorkerne genutzt werden, ohne einen zu großen Verwaltungsaufwand für die Prozesse zu generieren. In Zeile 14 wird dann ein entsprechender Pool von Prozessen angelegt und durch die Anweisung der Zeilen 15 und 16 spezifiziert, dass mittels dieser Prozesse so häufig wie Prozesse vorhanden sind asynchron jeweils \code{big\_n} geteilt durch die Anzahl der Prozesse zufällige Spiele simuliert werden. Da die entsprechende Funktion eine Ganzzahl erwartet, kommt an dieser Stelle die Ganzzahldivison \code{//} zum Einsatz. Dadurch ergibt die Summe aller durchgeführten Simulationen ggf. nicht \code{big\_n}; bei entsprechend großen Werten kann dies jedoch vernachlässigt werden.
\\Da die Spiele asynchron simuliert werden, muss die Berechnung zunächst durch Aufruf der Funktion \code{get} an jedem Listenelement angestoßen werden. Für das erste Element geschieht dies in Zeile 17. Für die weiteren Elemente erfolgt dies in der Schleife zur Zusammenführung der Ergebnisse. In Zeile 20 werden dann alle Prozesse wieder geschlossen.
\\Nun muss anhand der Daten zu gewonnenen und insgesamt gespielten Spiele für jeden Zug die Gewinnwahrscheinlichkeit berechnet werden. Dies erfolgt in den Zeilen 21 bis 23 indem der Quotient aus den beiden Werten gebildet wird (Z. 23)
\\Nun wird jener Zug mit der größten Gewinnwahrscheinlichkeit ermittelt (Z. 24) und and die aufrufende Funktion zurückgegeben (Z. 25).      
\begin{lstlisting}[caption = {get\_move Funktion des Monte-Carlo Agenten}, language = python, captionpos = t , numbers=left, label={lst:ab1}]
    def get_move(self, game_state: Othello):
        if self.use_start_lib and game_state.get_turn_nr() < 21: 
            moves = self.start_tables.get_available_moves_of_start_tables(game_state)
            if len(moves) > 0:
                return UtilMethods.translate_move_to_pair(moves[random.randrange(len(moves))])
        self.move_probability.clear()
        own_symbol = game_state.get_current_player()
        if self.preprocessor is not None:
            self.preprocessor(game_state, self.preprocessor_parameter, self.heuristic)
        if not self.use_multiprocessing:
            winning_statistics = MonteCarlo.play_n_random_games(own_symbol, game_state, self.big_n)
        else:
            number_of_processes = mp.cpu_count()
            pool = mp.Pool(processes=number_of_processes)
            list_of_stats = [pool.apply_async(MonteCarlo.play_n_random_games, args=(own_symbol, 
            		game_state.deepcopy(), self.big_n // number_of_processes)) for _ in range(number_of_processes)]
            winning_statistics = list_of_stats[0].get()
            for single_list in list_of_stats[1:]:
                MonteCarlo.combine_statistic_dicts(winning_statistics, single_list.get())
            pool.close()
        for single_move in winning_statistics:
            (games_won, times_played) = winning_statistics[single_move]
            self.move_probability[single_move] = games_won / times_played
        selected_move = max(self.move_probability.items(), key=operator.itemgetter(1))[0]
        return selected_move
\end{lstlisting}

\subsection{Alpha-Beta Pruning}
Der Agent \mxZitat{Alpha-Beta Pruning} basiert auf dem in Kapitel \ref{ab-pruning} beschriebenen Prinzip des Alpha-Beta Abschneidens. Wie bereits erläutert handelt es sich dabei um eine Tiefensuche, bei der weniger vielversprechende Zweige nicht bis zum Ende ausgewertet werden.
\\Wie in \ref{ab-depth-limited} erläutert wird dabei ab einer gewissen Suchtiefe eine Heuristik zur Bewertung eines Spielzustandes herangezogen. Dadurch, muss nicht der komplette Baum bis zum Ende ausgewertet werden.  
\\Nachfolgend wird die in der Datei \code{alphaBetaPruning.py} bedindliche Implementierung besprochen.
\subsubsection{Parameter}
Auch das detaillierte Verhalten des Agenten \mxZitat{Alpha-Beta Pruning} kann durch verschiedene Parameter beeinflusst werden. Sie lauten:
\begin{itemize}
\item \code{\_use\_start\_libs}: Bool'scher Wert der angibt ob Startbibliotheken verwendet werden sollen.
\item \code{\_search\_depth}: Gibt die Tiefe an, ab der einzelne Zweige nicht weiter verfolgt werden und stattdessen die Heuristik zur Zustandsbewertung verwendet wird.
\item \code{\_heuristic}: Eine der in Kapitel \ref{Heuristiken} beschriebenen Heuristiken.
\item \code{\_use\_monte\_carlo}: Bool'scher Wert der angibt ob in der Tiefe \code{search\_depth} + 1 statt der Heuristik das Prinzip des Monte Carlo Agentens zur Bewertung der Züge verwendet werden soll.
\item \code{\_mc\_count}: Anzahl der simuliert Spiele wenn das Monte Carlo Prinzip zur Bewertung des Zustandes verwendet wird.
\end{itemize}
\subsubsection{Die Funktion \code{value}}
Die in Listing \ref{lst:ab-value} abgedruckte Funktion \code{value} entspricht im wesentlichen der in Listing \ref{lst:abprun} abgedruckten und in \ref{ab-basics-impl} besprochenen \mxZitat{value}-Funktion des Alpha-Beta Abschneiden Algorithmus.
\\Hier soll einzig auf den sich unterscheidenden Basisfall (Zeile 3-6) eingegangen werden. Ist ein Endzustand erreicht, so ist das Spiel beendet und die Abfrage in Zeile 3 wird positiv ausgewertet. In diesem Fall wird der Wert der \code{utility}-Funktion für den aktuellen Spieler zurück gegeben (Z. 4). Um das Gewinnen bzw. Verlieren jedoch deutlich stärker zu gewichten als die Bewertungen der Heuristik, wird dies zuvor mit $1000$ multipliziert.
\\Ist die maximale Suchtiefe erreicht, so wird die Abfrage in Zeile 5 positiv ausgewertet. In diesem Fall wird die Heuristik zur Zustandsbewertung herangezogen (Z. 6)
\begin{lstlisting}[caption = {\code{value} Funktion des Alpha-Beta Spielers}, language = python, captionpos = t , numbers=left, label={lst:ab-value}]
    @staticmethod
    def value(game_state: Othello, depth, heuristic, alpha=-1, beta=1):
        if game_state.game_is_over():
            return game_state.utility(game_state.get_current_player()) * 1000
        if depth == 0:
            return heuristic(game_state.get_current_player(), game_state)
        val = alpha
        for move in game_state.get_available_moves():
            next_state = game_state.deepcopy()
            next_state.play_position(move)
            val = max({val, -1 * AlphaBetaPruning.value(next_state, depth - 1, heuristic, -beta, -alpha)})
            if val >= beta:
                return val
            alpha = max({val, alpha})
        return val
\end{lstlisting}
\paragraph{Änderungen an \code{value\_monte\_carlo}}
Wird statt der Heuristik zur Bewertung der \mxZitat{Monte-Carlo Agent} herangezogen, so wird statt der Funktion \code{value} die angepasste Funktion \code{value\_monte\_carlo} aufgerufen. Dabei wird in dem in Listing \ref{lst:ab-value} in Zeile 6 beschriebenen \code{if}-Zweig eine Bewertung aller möglichen Züge vorgenommen und die Gewinnwahrscheinlichkeit des besten Zuges zurückgegeben. 

\subsubsection{Die Funktion \code{get\_move}}
Eine Funktion \code{get\_move} wird von allen Agenten bereitgestellt und in der \code{main-game.py} zur Auswahl eines Zuges gerufen. Beschrieben wird der Zug durch ein Paar, welches die Koordinaten auf dem Spielbrett darstellt.
\\Nachfolgend wird die in Listing \ref{lst:ab-get-move} abgedruckte Funktion diskutiert:
\\Die Übergabeparameter, sowie die Zeilen bis einschließlich 5 \improvement{anders} sind identisch zu der Implmentierung der im Kapitel \ref{mc-getmove} diskutierten \code{get\_move}-Funktion des \mxZitat{Monte-Carlo}-Agenten.
\\In Zeile 6 wird ein Wörterbuch zur Speicherung der Bewertungen der Züge gemäß der \code{value}-Funktion angelegt. In diesem wird später die Bewertung als Schlüssel und als dazugehörigen Wert die Liste aller Züge die diese Bewertung erhalten haben gespeichert werden. Diese Datenstruktur wird durch die Schleife in den Zeilen 7 bis einschließlich 17 aufgbaut in dem über alle legalen Züge iteriert wird:
\\In den Zeilen 8 bzw. 9 wird der Ausgangszustand kopiert und der in der aktuellen Schleifeniteration betrachtete Zug \code{move} ausgeführt. Nun wird die Bewertung mittels der \code{value}-Funktion vorgenommen. Dabei wird unterschieden ob gemäß des Parameters \code{\_use\_monte\_carlo} in der Tiefe \code{\_search\_depth} mittels der Funktion \code{value\_monte\_carlo} das Monte-Carlo Prinzip zur Bewertung herangezogen werden soll (Z. 10f) oder ob mittels der Funktion \code{value} die Heuristik verwendet wird (Z. 13f).
\\Nun wird überprüft ob bereits Spielzüge mit dieser Bewertung in \code{best\_moves} gespeichert sind (Z. 15). Ist dies nicht der Fall, so wird die Bewertung mit der leeren Liste initialisiert (Z. 16). Anschließend wird der gerade betrachtete Zug \code{move} an die entsprechende Liste angehängt.
\\Sobald alle legalen Züge betrachtet wurden, wird die maximale Bewertung ermittelt (Z. 18) und ein zufälliger Zug mit dieser Bewertung zurückgegeben (Z. 19).
\begin{lstlisting}[caption = {get\_move Funktion des Alpha-Beta Spielers}, language = python, captionpos = t , numbers=left, label={lst:ab-get-move}]
    def get_move(self, game_state: Othello):
        if self._use_start_lib and game_state.get_turn_nr() < 21:
            moves = self._start_tables.get_available_moves_of_start_tables(game_state)
            if len(moves) > 0:
                return UtilMethods.translate_move_to_pair(moves[random.randrange(len(moves))])
        best_moves = dict()
        for move in game_state.get_available_moves():
            next_state = game_state.deepcopy()
            next_state.play_position(move)
            if self._use_monte_carlo:
                result = -AlphaBetaPruning.value_monte_carlo(next_state, self._search_depth - 1, self._heuristic,
                                                             mc_count=self._mc_count)
            else:
                result = -AlphaBetaPruning.value(next_state, self._search_depth - 1, self._heuristic)
            if result not in best_moves.keys():
                best_moves[result] = []
            best_moves[result].append(move)
        best_move = max(best_moves.keys())
        return best_moves[best_move][random.randrange(len(best_moves[best_move]))]
\end{lstlisting}
