% This file was created with Citavi 6.2.0.12

@book{Russell.2016,
 author = {Russell, Stuart J. and Norvig, Peter},
 year = {2016},
 title = {Artificial intelligence: A modern approach},
 publisher = {Pearson},
 isbn = {978-0-13-604259-4},
 series = {Always learning}
}

@inproceedings{chaslot2008monte,
  title={Monte-Carlo Tree Search: A New Framework for Game AI.},
  author={Chaslot, Guillaume and Bakkes, Sander and Szita, Istvan and Spronck, Pieter},
  booktitle={AIIDE},
  year={2008}
}

@article{browne2012survey,
  title={A survey of monte carlo tree search methods},
  author={Browne, Cameron B and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M and Cowling, Peter I and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  journal={IEEE Transactions on Computational Intelligence and AI in games},
  volume={4},
  number={1},
  pages={1--43},
  year={2012},
  publisher={IEEE}
}

@article{StroetmannAI19,
  title={An Introduction to Articial Intelligence - Lecture Notes in Progress},
  author={Stroetmann, Prof. Dr. Karl},
  year={2019}
}

@article{Auer.2002,
 author = {Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
 year = {2002},
 title = {Finite-time analysis of the multiarmed bandit problem},
 pages = {235--256},
 volume = {47},
 number = {2-3},
 journal = {Machine learning}
}


@inproceedings{Tokic.2010,
 abstract = {This paper presents ``Value-Difference Based Exploration'' (VDBE), a method for balancing the exploration/exploitation dilemma inherent to reinforcement learning. The proposed method adapts the exploration parameter of $\backslash$epsilon-greedy in dependence of the temporal-difference error observed from value-function backups, which is considered as a measure of the agent's uncertainty about the environment. VDBE is evaluated on a multi-armed bandit task, which allows for insight into the behavior of the method. Preliminary results indicate that VDBE seems to be more parameter robust than commonly used ad hoc approaches such as $\backslash$epsilon-greedy or softmax.},
 author = {Tokic, Michel},
 title = {Adaptive $\backslash$epsilon-Greedy Exploration in Reinforcement Learning Based on Value Differences},
 pages = {203--210},
 publisher = {{Springer Berlin Heidelberg}},
 isbn = {978-3-642-16111-7},
 editor = {{Dillmann, R{\"u}diger and Beyerer, J{\"u}rgen and Hanebeck, Uwe D. and Schultz, Tanja}},
 booktitle = {KI 2010: Advances in Artificial Intelligence},
 year = {2010},
 address = {Berlin, Heidelberg}
}

@misc{ Ortiz.,
    author = "{Ortiz, George and Berg, Matthias}",
    title = "Er{\"o}ffnungsstrategie",
    howpublished = "\\\url{http://berg.earthlingz.de/ocd/strategy3.php}",
    note = "[Online; accessed 20-January-2019]"
}
@misc{ Berg,
    author = "{Berg, Matthias}",
    title = "Strategief√ºhrer",
    howpublished = "\url{http://berg.earthlingz.de/ocd/strategy2.php}",
    note = "[Online; accessed 20-January-2019]"
}

@misc{ wikibooks,
    author = "{o.V.}",
    title = "Spiele: Othello",
    year = "2015",
    howpublished = "\url{https://de.wikibooks.org/wiki/Spiele:_Othello}",
    note = "[Online; accessed 20-January-2019]"
}

@misc{nijssen_2007,
	title={Playing Othello Using Monte Carlo},
	author={Nijssen, J. A. M.}, 
	year={2007}, 
	month={Jun}
}
