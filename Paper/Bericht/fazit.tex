\chapter{Fazit}
\label{Fazit}
\authormax

In diesem Kapitel werden die Ergebnisse der Arbeit bewertet und ein Ausblick über weitere Forschungsgegenstände gegeben.
\\Im ersten Abschnitt werden dazu zunächst die präsentierten Agenten bewertet und weitere Anpassungsmöglichkeiten aufgezeigt.
\\Der zweite Abschnitt nimmt eine Bewertung der eingesetzten Heuristiken vor, indem die Variation der Ergebnisse eines Agenten bei der Verwendung der verschiedenen Heuristiken betrachtet wird.
\\Im dritten und letzten Abschnitt wird schließlich der erwähnte Ausblick gegeben.   

\section{Bewertung der Agenten}
Zunächst werden also die präsentierten Agenten bewertet indem sie zum einen mit dem \mxZitat{Random}-Agenten und zum anderen Untereinander verglichen werden.
\\Zu jedem Agenten werden dabei weitere Anpassungsmöglichkeiten genannt und die möglichen Auswirkungen einer solchen Anpassung besprochen.
\subsection{Der Agent \mxZitat{\mc}}
\authormax
Zunächst wird auf die Leistung des Agenten \mxZitat{\mc} gegen den zufällig agierenden Agenten eingegangen. Dabei finden auch einige noch offene Fragen Erwähnung. Den Abschluss dieses Abschnitts bildet schließlich die Beschreibung weiterer Anpassungsmöglichkeiten des Agenten.  
\paragraph{Leistung gegen den Agenten \mxZitat{Random}}
Wie in Tabelle \ref{tbl:cmp-results} anhand der Vergleiche 1 bzw. 6 deutlich wird, hat der \mxZitat{\mc}-Agent sämtliche der insgesamt 2000 Testspielen gegen den \mxZitat{Random}-Agenten gewonnen. Dabei ist bis auf eine geringe Abweichung der durchschnittlich benötigten Rechenzeit pro Spiel unerheblich ob der Agent als Spieler 1 oder Spieler 2 auftritt. Damit ist der mit dem Spiel des Agenten verbundene Rechenaufwand in so fern berechtigt, dass er bessere Ergebnisse liefert als ein Agent der zufällige Züge durchführt.
\\Im Vergleich mit menschlichen Spielern ist jedoch davon auszugehen, dass diese keine zufälligen Züge ausführen. Stattdessen ist, ein entsprechendes Spielniveau vorausgesetzt, damit zu rechnen, dass ein Spieler Kenntnisse über das Spiel und außerdem durch Erfahrung verfeinerte Strategien einbringt. Dieser Vergleich konnte im Rahmen der Arbeit leider nicht durchgeführt werden und ist damit eine Fragestellung für weitere Untersuchungen.  
\paragraph{Weitere Variationsmöglichkeiten}
In den zur Bestimmung der für den Agenten verwendeten Parameter konnte beobachtet werden, dass die Gewinnwahrscheinlichkeit des Agenten von der Anzahl der mittels der \mc\ Methode simulierten Spiele abhängt. In den betrachteten Fällen konnte durch die Erhöhung der Anzahl simulierter Spiele, also die Erhöhung des Parameters \code{big\_n}, im Allgemeinen eine Verbesserung der Gewinnwahrscheinlichkeit des Agenten erzielt werden. Gleichzeitig hat \cite{nijssen_2007} gezeigt, dass sich dieser Effekt mit steigender Größe von \code{big\_n} abschwächt. Zusätzlich dazu steigt mit der Anzahl der durchgeführten Simulationen auch die benötigte Rechenzeit. Zu Untersuchen wäre daher ob das überschreiten der Rechenzeit von fünf Minuten auf dem Referenzgerät eine weitere Verbesserung bringt und damit den erhöhten Aufwand rechtfertigt.

\subsection{Der Agent \mxZitat{\abp}}
\authorpatrick
In diesem Abschnitt findet sich, ähnlich dem vorherigen, zunächst ein Vergleich des \mxZitat{\abp} Agenten mit dem zufällig agierenden Agenten. Im Anschluss werden weitere Variationsmöglichkeiten besprochen. 
\paragraph{Leistung im Vergleich zum Agenten \mxZitat{Random}}
Im Vergleich mit dem zufällig spielenden Agenten gewann der Agent \mxZitat{\abp} in allen Fällen bis auf den Vgl. 2 mehr Spiele. Deutlich wird auch, dass der Erfolg des Agenten im wesentlichen von der Strategie zur Bewertung der Zustände in der maximalen Suchtiefe abhängt. Auf die dabei verwendeten einzelnen Heuristiken, wird im Abschnitt \ref{sect:Fazit:Heuristiken} genauer eingegangen.
\\Kommt statt einer Heuristik in den Blättern des Baumes jedoch \mc\ zum Einsatz, so werden nochmals deutlich bessere Ergebnisse erzielt. Dafür dauert die Berechnung eines einzelnen Zuges nochmals wesentlich länger. Damit ist die Kombination der \ababs\ Methode und der \mc\ Methode als ein, zwar eher rechenintensiver, jedoch durchaus erfolgreicher Ansatz zu betrachten. Besonders hervorzuheben ist dabei, dass zur Umsetzung kein Spezialwissen für \ot\ benötigt wird. Zu Untersuchen wäre in wie weit dieser Aspekt auf andere Spiele übertragbar ist.
\\An dieser Stelle ist damit festzuhalten, dass auch der \mxZitat{\abp}-Agent, die Wahl einer guten Heuristik vorausgesetzt, den Rechenaufwand insofern rechtfertigt, das Spiel des Agenten meist besser ist als das des zufällig agierenden. Wie oben wäre auch hier die Gewinnwahrscheinlichkeit gegen menschliche Spieler Gegenstand weiterer Untersuchungen.
\\Auffällig ist außerdem, dass im Vergleich zu dem \mxZitat{\mc}-Agenten im Spiel mit dem \mxZitat{Random}-Agenten eine deutlich längere Rechenzeit benötigt wird um zu einem insgesamt schlechteren Ergebnis zu kommen. So gelang es dem Agenten \mxZitat{\mc} alle Spiele gegen den Agenten \mxZitat{Random} zu gewinnen. Der hier besprochene Agent gewinnt jedoch, selbst in seiner besten Variation, nur $83\%$ der Spiele. Auf die Performance der beiden Agenten im direkten Vergleich wird in Abschnitt \ref{subsec:Fazit:AgentenVgl} eingegangen.
\paragraph{Weitere Variationsmöglichkeiten}
Gemäß der in Kapitel \ref{ab-pruning} beschriebenen Theorie hinter dem Agenten \mxZitat{\abp} kann durch eine größere Suchtiefe \code{search\_depth} die Genauigkeit mit der die Bewertung eines Zuges der realitätsgetreuen Bewertung entspricht erhöht werden. Da sich der Suchbaum mit jeder Ebene stärker verzweigt ist in diesem Fall jedoch mit einer exponentiell steigenden Rechenzeit zu rechnen. Mit der vorgestellten Implementierung wäre dies unter dem Zeitaspekt jedoch keine Option. Entsprechend stellt sich hier die Frage in wie weit der Algorithmus des \ababs\ parallelisiert werden kann, um alle verfügbaren Prozessoren eines Computersystems zu benutzen und damit innerhalb der fünf Minuten Rechenzeit die der Anwender bereit ist zu warten, den Suchbaum noch tiefer zu durchsuchen.


\subsection{Vergleich der Agenten \mxZitat{\mc} und \mxZitat{\abp}}
\authorpatrick
\label{subsec:Fazit:AgentenVgl}
Der \mxZitat{\mc} Agent spielt sowohl bei der Verwendung der \mxZitat{Cowthello}-Heuristik als auch bei der Verwendung der \mc -Variante deutlich besser als der \mxZitat{\abp} Agent. Dieses Ergebnis kann dabei sogar bei einer im Vergleich deutlich kürzeren Rechenzeit erreicht werden.
\\Da der \mxZitat{\mc} Agent in der Spieltheorie einfach nur ab einem aktuellen Spielzustand eine gewissen Anzahl von zufälligen Spielen simuliert und anhand der Ausgänge dieser Simulationen den besten Folgezug ermittelt, kommt dabei keinerlei Wissen über das Spielprinzip des Spiels \ot\ zum Einsatz. 
\\Von der Verwendung des \mxZitat{\abab}-Verfahren wurde sich im Rahmen dieser Arbeit erhofft durch die Verwendung von Fachwissen in Form einer Heuristik bessere Ergebnisse zu erzielen. Das verfahren basiert grundlegend auf einer angepassten MiniMax-Suche. Dieser liegt die Tatsache zugrunde, dass gute Züge des eines Spielers gleichzeitig schlechte Züge des Gegners sind.
\\Der erwartete Effekt trat allerdings nicht ein. Dies kann mehrere Gründe haben:
\begin{itemize}
\item Die verfügbaren Heuristiken, welche in den Blattknoten der \mxZitat{\abp} Suche verwendet werden, sind zu ungenau. Beispielsweise wurde in Kapitel \ref{fz:h_smc} festgestellt, dass die Heuristik \mxZitat{Stored \mc} ungeeignet ist. Durch die große Spanne der Gewinnwahrscheinlichkeiten des \mxZitat{\abp} Agenten je nach verwendeter Heuristik ist es denkbar, dass noch deutlich bessere Heuristiken entwickelt werden können.
\item Die \mxZitat{\abp} Suche benötigt sehr viel Zeit. Durch die große Verzweigung existieren sehr viele Blattknoten, für welche ein Wert ermittelt werden muss. Dies geschieht durch die Verwendung einer Heuristik oder der \mxZitat{\mc} Suche.
\\In der Zeit, welche der \mxZitat{\abp} Agent zur Suche benötigt, kann der \mxZitat{\mc} Agent deutlich mehr zufällige Spiele simulieren. Dadurch wird der Vorteil des \mxZitat{\abp} Agenten durch die große Anzahl der durchgeführten Züge ausgeglichen.
\item Die \mxZitat{\abp} Suche verfügt bei den hier präsentierten Agenten über eine zu geringe Suchtiefe. Durch eine größere Suchtiefe werden bessere Ergebnisse erreicht. Allerdings steigt die Berechnungszeit eines Zuges selbst bei der Erhöhung der Suchtiefe nur um eins sehr stark an. Dadurch kann der Agent nur bis zu einer bestimmten Suche (max. 5) eine \mxZitat{\abp} Suche durchführen, bevor die Wartedauer auf den nächsten Zug den erwarteten Nutzen übersteigt. 
\end{itemize} 
\section{Bewertung der Heuristiken}
\authormax
\label{sect:Fazit:Heuristiken}
Im nachfolgenden Abschnitt wird auf die jeweilige Leistung der einzelnen Heuristiken in den durchgeführten Vergleichen eingegangen. Insbesondere bei der \mxZitat{Stored \mc\ Heuristik} werden dabei mögliche Verbesserungsmöglichkeiten besprochen.  
\subsection{Die Heuristik \mxZitat{Nijssen 07}}
Die Implementierung der von \cite{nijssen_2007} vorgeschlagenen Heuristik kann in den hier durchgeführten Vergleichen nicht überzeugen. Tritt der Agent der sie im Spiel gegen den \mxZitat{Random}-Agenten einsetzt als Spieler 1 auf, so werden bei ihrem Einsatz sogar weniger Spiele gewonnen als der zufällig spielende Agent gewinnt (Vgl. 2). Zwar spielt der Agent besser wenn er als Spieler 2 auftritt (Vgl. 7), jedoch legt das Ergebniss des Vergleiches des zufällig spielenden Agenten mit sich selbst (Vgl. 0) nahe, dass der als Spieler 2 auftretende Agent im wesentlichen eine um rund 10\% höhere Gewinnchance hat. Diese Marge deckt sich im wesentlichen mit der angesprochenen Verbesserung.
\\Damit kann die Heuristik, ohne weitere Verbesserungen, nicht für den Einsatz empfohlen werden. Von einem Einsatz bei der Untersuchung des Spielverhaltens des \mxZitat{\abp}-Agenten gegen einen menschlichen Spieler ist abzusehen. 
\subsection{Die Heuristik \mxZitat{Stored \mc}}
\authorpatrick
\label{fz:h_smc}
Nutzt der \mxZitat{\abp}-Agent die \mxZitat{Stored \mc} Heuristik so, gewinnt er in beiden Spielkombinationen häufiger als der \mxZitat{Random} Agent (siehe Abbildung \ref{tbl:cmp-results} Vergleiche 3 und 8). Im Vergleich mit den anderen Heuristiken ist die Gewinnwahrscheinlichkeit jedoch sehr gering.
\\Im Spiel \mxZitat{AB (Stored \mc\ Heuristik) } gegen \mxZitat{Random} (siehe Vergleich 3) gewinnt der Agent in 1000 Spielen nur vier Spiele mehr als der zufällige Spieler (458 zu 454). In den 1000 Spielen \mxZitat{Random} gegen \mxZitat{AB (Stored \mc\ Heuristik)} gewinnt die Heuristik mit 446 zu 550 gewonnenen Spielen (siehe Vergleich 8).
\\Aus den Vergleichen 3 und 8 lassen sich folgende Erkenntnisse ableiten:
\begin{itemize}
\item Der Agent \mxZitat{\abp} gewinnt bei der Verwendung der \\\mxZitat{Stored \mc} Heuristik als zweiter Spieler deutlich mehr Spiele als als erster Spieler.
\item Wird der Agent als erster Spieler eingesetzt ergibt sich keine deutlich höhere Gewinnwahrscheinlichkeit als die des zufälligen Spielers. Dies bedeutet, dass der Agent sehr schlecht spielt, es also genauso gut wäre Züge zufällig auszuwählen. 
\item Auffällig sind die 88 Spiele, welche im Vergleich 3 unentschieden endeten. Im Gegensatz dazu gab es im Vergleich 8 nur vier unentschiedene Spiele. Die Gewinnwahrscheinlichkeit des zufälligen Spielers bleibt allerdings annähernd gleich bei 45,4\% bzw. 44,6\%. Man könnte dieses Ergebnis so interpretieren, dass der Agent in Vergleich die Spiele zwar nicht gewinnen konnte, aber immerhin verhindern konnte, dass diese Spiele verloren wurden.
\item Die Spiele im Vergleich 8 sind durchschnittlich 37,8 Sekunden schneller die Spiele im Vergleich 3.
\end{itemize}
Die Nutzung der Heuristik \mxZitat{Stored \mc} wird aufgrund der o.g. Ergebnissen nicht empfohlen.
\\Es gibt mehrere mögliche Ursachen der schlechten Gewinnwahrscheinlichkeiten der Heuristik.
\vspace{0.5cm}
\\Die erste Ursache ist, dass die Datenbank, auf welcher die Heuristik basiert, nicht die Gewinnwahrscheinlichkeit des Spielers bei der Durchführung eines Zuges in der aktuellen Zugnummer im aktuellen Spiel liefert. Stattdessen gibt die Datenbank die Gewinnwahrscheinlichkeit des Spielers zurück, der in der aktuellen Zugnummer den Zug ausführt, zurück.
\\Der Unterschied zwischen den Aussagen besteht darin, dass die Datenbank den aktuellen Spielzustand (bereits durchgeführte Spielzüge) vernachlässigt und nur die statistische Wahrscheinlichkeit über alle Züge zurückgibt, in welchen in der aktuellen Zugnummer der Zug zu einem Gewinn geführt hat.
\\Dadurch können Spielsituationen auftreten, in welchen der Zug mit der, laut Datenbank, höchsten Gewinnwahrscheinlichkeit schlechter ist als ein Zug mit einer vermeintlich geringeren Gewinnwahrscheinlichkeit, da die jeweilige Spielsituation die Wahrscheinlichkeiten stark beeinflusst.
\vspace{0.5cm}
\\Es müsste auch evaluiert werden, ob die Zusammenfassung der Spielfelder in zehn Spielkategorien eine zu starke Vereinfachung des Spielfeldes darstellt. Das Spielfeld ist zwar symmetrisch aufgebaut, es könnten aber dennoch Seiteneffekte auftreten.
\vspace{0.5cm}
\\Dies führt zu einer weiteren möglichen Ursache der schlechten Heuristik. Aus den in der Datenbank gespeicherten Tripel aus gewonnen Spielen des ersten / zweiten Spielers und der Gesamtanzahl der durchgeführten Spiele wird nur die Gewinnwahrscheinlichkeit berechnet. Die Gesamtanzahl der durchgeführten Spiele wird allerdings nicht berücksichtigt. Es kann durchaus vorkommen, dass einzelne Feldkategorien unterschiedlich oft gespielt werden. So kann eine Feldkategorie sehr selten gespielt werden, dann aber eine relativ hohe Gewinnwahrscheinlichkeit besitzen, und eine Feldkategorie sehr oft mit einer geringeren Gewinnwahrscheinlichkeit gespielt werden. Die Heuristik bevorzugt in diesem Fall die selten gespielte Feldkategorie, da die Gewinnwahrscheinlichkeit höher ist. Da die Gesamtanzahl aller durchgeführten Spielzüge einer Zugnummer, sieht man von vorzeitig beendeten Spielen ab, konstant sind (rd. 140.000), ist es u.U. auch sinnvoll die Gesamtanzahl der Spiele einer Feldkategorie der verfügbaren Feldkategorien in die Berechnung der Heuristik einzubinden.

\subsection{Die Heuristik \mxZitat{Cowthello}}
Die \mxZitat{Cowthello} Heuristik bietet die höchsten Gewinnwahrscheinlichkeiten der \mxZitat{\abp} Heuristiken. Folgende Ergebnisse können aus den Vergleichen 4 und 9 der Tabelle \ref{tbl:cmp-results} abgeleitet werden:
\begin{itemize}
\item In den 1000 Spielen des \mxZitat{\abp} Agenten mit der \mxZitat{Cowthello} Heuristik gegen den \mxZitat{Random} Agenten gewinnt der \mxZitat{\abp} \\Agent 564 zu 324 Spiele.
\item Die große Zahl von 112 unentschiedenen Spielen fällt bei dieser Heuristik ebenfalls auf.
\item In den 1000 Spielen des \mxZitat{Random} Agenten gegen den \mxZitat{\abp} Agenten mit der \mxZitat{Cowthello} Heuristik gewinnt der \mxZitat{\abp} \\Agent 709 zu 289 Spiele.
\item Die durchschnittliche Spielzeit des Agenten ist als zweiter Spieler ebenfalls geringer als die des Agenten als erster Spieler. Die Spielzeit der \mxZitat{Cowthello} Heuristik ist die kleinste aller verwendeten Heuristiken.
\end{itemize}
Damit ist die \mxZitat{Cowthello}-Heuristik die beste der betrachteten Heuristiken. Entsprechend ist ihr Einsatz für den Agenten \mxZitat{\abp} zu empfehlen.

%\section{Bewertung der Vorgehensweise}

\section{Ausblick}
\authorpatrick
\paragraph{Weitere Verfolgung des Ansatzes der \mxZitat{Stored \mc}-Heuristik}
Die in der \mxZitat{Stored \mc} Heuristik verwendetet Datenbank könnte womöglich zur Erstellung eines verbesserten Agenten benutzt werden. Die Funktionsweise des neuen Agenten entspräche dabei im wesentlichen der des \mxZitat{\mc} Agenten. Der Unterschied bestünde darin, bei der Auswahl von Zügen in den simulierten Spielen einen zufälligen Zug so zu wählen, dass dieser jeweils mit einer der in der Datenbank für diesen Zug gespeicherten Wahrscheinlichkeit proportionalen Wahrscheinlichkeit ausgewählt wird. Werden die Ergebnisse der simulierten Spiele zusätzlich in der Datenbank gespeichert, so verbessert sich der Agenten mit jedem gespielten Spiel.
\\Dieser Prozess ist aber zwangsläufig mit Schreibzuggriffen oder mindestens das Verändern des Datenbankenobjektes verbunden. Dies hat zwei schwerwiegende Auswirkungen:
\begin{itemize}
\item Die Parallelisierung der gleichzeitigen Ausführung zufälliger Spiele ist schwieriger, da auf Dateiebene nur ein Thread gleichzeitig in die Datenbank schreiben kann.
\item Die zusätzliche Datenbankinteraktion benötigt mehr Zeit.
\end{itemize}
Das Resultat der beiden Auswirkungen ist, dass die Anzahl der durchgeführten zufälligen Spiele reduziert werden muss wenn die Berechnungszeit nicht wachsen soll.
\\Es ist zu evaluieren, ob der Mehrwert der Datenbanknutzung größer ist als der bisherige \mxZitat{\mc} Agent, welcher eine höhere Anzahl an zufällig durchgeführter Spiele besitzt.
%\paragraph{Bedeutung für die Methode}

